[["index.html", "ElementDB the Book 34838fa 第 1 章 序言", " ElementDB the Book 34838fa ar8327 2024-02-13 第 1 章 序言 构建一个数据库是一项庞大、复杂的工作，我也并不是专业有过数据库构建经验的人，所以，我想在文章的开篇就说明白，接下来这些文章的目的、受众以及我将如何展开。 首先，这并不是一份专业性的数据库材料。我会尽可能将我的想法描述清楚，但我描述的内容中可能有不专业、不准确的地方，欢迎指正。这份资料本身的受众是对这些话题有兴趣但没有专业背景的业余爱好者。 再次，这份资料的目的是记录我个人学习数据库相关知识时学习到的知识，以及我自己在实现数据库时自己的思考。我通过将这些知识整理成系统性资料的方式来提高我自身对知识的理解，也能帮助需要的朋友更好地学习。 最后，来介绍一下这份资料的组织形式。 首先聊一聊接下来这些资料的逻辑： 我会先讨论一些关于数据库系统的通用知识，例如什么是事务、什么是 SQL 、什么样的系统是一个数据库系统。在这一过程中，我会尽可能展示这些问题的复杂性，通过展示问题的复杂性，可以让读者对之后解决问题的过程产生兴趣，同时，也有利于激发新的思考。 随后，我会介绍一个数据库系统大致应该有哪些组成部分，各个部分的作用，以及建立一个数据库的模型。在之后，我会详细展开每个部分的理论基础和系统设计，辅以部分实践和杂谈。 我接下来写的资料会大概属于四个分类： 理论，这部分文章会相对严肃一些，阐述一些关于数据库系统的基础理论。例如，要阐述 B+ 树的设计、并发控制机制等，这部分内容会相对干一点，但这是后续所有工作的理论基础，保证我们系统的正确性。 系统设计，这部分在理论的基础上，会讨论在工程上实际实现系统的取舍。同一种理论上的系统模型，有多种实现方式，而不同的实现方式，会产生系统实际性能表现等方面的不同，这就涉及到取舍，是需要重点讨论的。 实践，这部分并不全部是要介绍我写的代码，甚至介绍代码的工作可能只占一小部分，也想设计一些小实验来测试、证实我在文章中所说的观点。我推荐读者也做一下这些实践，可能是自己写一份测试性能的代码，也可能是自己写一个 mmap 的 demo ，通过做这些事情能提高读者的编程能力，这是最基础的能力。 杂谈，杂谈这一块我会发散地讨论一些和数据库系统本身无关，但可能有借鉴价值，或者属于基本素质的内容。 ar8327 2023 年 10 月 "],["intro.html", "第 2 章 问题引入 2.1 构建一个员工信息管理系统 2.2 员工信息管理系统的问题", " 第 2 章 问题引入 2.1 构建一个员工信息管理系统 在动手设计实现数据库之前，不妨先花一点时间头脑风暴一下数据库是什么。 其实，大部分的程序员在编写应用程序的时候，都不会意识到数据库承担了多少工作，这恰恰说明了数据库概念的成功，将数据存储、并发控制、一致性保证等功能从应用中切分出来，并且运用“事务”等概念来实现存储层功能的接口化，是一项了不起的工作。 为了更好地帮助读者认识到数据库的概念，我先从尝试着在不使用数据库的情况下实现一个员工信息管理系统开始，请读者和我一起思考，我们一起分析可能遇到的问题，并且思考数据库是如何解决它们的。 存储的逻辑结构 假设现在我们需要存储一些雇员的信息，这些信息这么定义：员工信息:(姓名, 电话, 年龄) 一条员工信息包括员工的姓名、 员工的电话和员工的年龄。 系统支持的功能 我们的信息管理系统要支持以下功能： 我们要可以插入新的员工信息到系统中，方便为新员工注册信息 我们要可以使用员工姓名查询员工信息，这样公司内的人能够通过姓名查询到他人的信息 为了存储信息，我们可以使用操作系统和文件系统提供的基本文件操作功能，可以在文件系统中创建空白文件，可以向文件中添加信息，也可以从任意位置读取文件。 系统的简易实现 有了上面这些条件，我可以给出一个比较简单的“员工信息管理系统”实现： 在这个实现中，我给每一条记录开启一个新的行，每一行中存储对应的员工信息， 每个员工信息的属性称为一列，每一行含有多个列，分别为员工信息的不同属性 在插入用户信息时，我保证写入的数据都符合这个格式 在查找用户信息时，我根据预先约定好的数据格式去解析数据文件，获取记录的雇员姓名，并返回所有符合要求的记录。 在具体实现上，为了遵循这一协议约定，我使用空文件来存储信息，在行与行之间使用 \\n 分割，同一行的列之间使用 &lt;SEP&gt; 分隔。 下面是一个简单的实现版本： import io class EmployeeManager: def __init__(self): self.DBFILE = &quot;employees.txt&quot; self.db = open(self.DBFILE, &quot;a+&quot;, encoding=&#39;utf-8&#39;) self.SEP = &quot;&lt;SEP&gt;&quot; def write(self, name, phone, age) self.db.seek(0, io.SEEK_END) self.db.write(&quot;{0}{1}{2}{3}{4}{5}\\n&quot;.format(name, self.SEP, phone, self.SEP, age, self.SEP)) self.db.flush() def findByName(self, name): self.db.seek(0) for line in self.db.readlines(): line = line.strip() line = line.split(self.SEP) if line[0] == name: self.db.seek(0) return line self.db.seek(0) return None if __name__ == &#39;__main__&#39;: emp = EmployeeManager() emp.write(&quot;Tom&quot;, &quot;+8613042552664&quot;, 32) emp.write(&quot;Marry&quot;, &quot;+8613142357624&quot;, 29) # Try to find Tom tom = emp.findByName(&quot;Tom&quot;) if tom: print(&quot;Tom exists&quot;) jack = emp.findByName(&quot;Jack&quot;) if jack: print(&quot;Jack exists&quot;) emp.write(&quot;Jack&quot;, &quot;+8613051531&quot;, 34) 最后，我们用一幅图来总结说明刚才我们所做的设计。用两个视图来概括，在文件的物理视图中，我们的文件如右图所示，而在程序和协议中，我们的数据表如左图所示。 图 2.1: 雇员文件逻辑视图 图 2.2: 雇员文件物理视图 2.2 员工信息管理系统的问题 在前文，我们一起实现了一个简单的员工信息管理系统。尽管这个数据库能够满足基本的功能需求，但它不可否认地存在一些缺陷。 在本文中，我会罗列这个信息管理系统可能出现的一些问题，并通过将这些问题分类，来识别数据库系统所做的工作、提供的保证： 与物理存储结构绑定的查询和写入逻辑 没有一种通用的查询语言，每个查找需求都需要编写单独的查找方法 findByName 方法、write 方法都直接与底层的数据存储方式耦合，查找数据的逻辑竟然需要精确到读取第几个字段，这是一种命令式 (imperative) 的做法，与目前的 SQL 语言的声明式查询是相对的，命令式的查询语言将底层实现暴露给最终用户，使得查询语言与底层实现耦合，这在日后是维护的噩梦 缺乏并发控制，读写操作互相排斥 数据库在写入的时候缺乏并发控制，可能出现两个进程同时写入一个文件的情况，造成文件损坏 findByName 方法同样不是并发安全的，可能在一个进程读取文件时另一个进程将文件 rewind 由于直接依赖底层文件的指针位置，读写无法同时进行 数据持久化与数据完整性检查 若在执行 write 方法的时候，flush 的时候系统断电，则会导致数据文件损坏，缺乏错误检查机制 若在执行 write 时，系统完成了 write 操作还没有flush时系统断电，会造成数据完全丢失 缺乏唯一索引约束能力 write 方法缺乏对记录的唯一性校验，如果用户犯错，系统就会写入多条相同的记录 性能问题 findByName 方法异常低效，每次都需要遍历整个文件查找记录，也不具备自己的缓存 缺乏字段类型、数据格式和存储低效 数据文件对数据格式缺乏校验和表示，写入的所有东西都会变成 string 数据文件用的是文本格式，空间效率十分低下 缺乏表结构灵活性 如果要新增一个员工性别字段怎么办？之前的数据如何迁移？ 尽管提出了许多问题，且似乎每一个这些问题都有简单的解决方式，但若要考虑一个能够解决所有问题的方案，似乎问题就会变得复杂。 举例来说，如果是为了解决缺乏唯一索引的问题，我们可以实现一个方法，在写入数据前先遍历整个文件，看看是不是有重复的数据，如果有的话就拒绝写入。但这样的实现也会让写入的性能进一步下降。 那么，有没有什么办法可以比较好地解决上面的全部问题呢？其实是有的。为了解决上面的问题，需要引入现代数据库系统的多个概念。从下一篇文章开始，我就会开始介绍数据库系统中的关键概念，并看看我们如何利用这些工具来解决上面的问题。 "],["intro-to-dbms.html", "第 3 章 DBMS简介 3.1 数据库系统发展简史 3.2 数据库系统的模块", " 第 3 章 DBMS简介 3.1 数据库系统发展简史 在 1960 年代，计算机刚被发明不久，当时计算机远没有普及，软件生态相较今天也十分简单。但在当时，就已经有大型公司尝试着使用计算机来管理数据了。 使用计算机来管理数据有很多好处，相较于传统的纸质数据管理方式，计算机一次性能够记录更多的数据，在数据的检索和管理上也更为容易，存在数据更不容易丢失等优势。 1960 年代主要的数据库系统是以 IDS 为代表的层级数据库。这么说可能会让读者没有概念，因此，为了描述数据库系统，我首先展开一下数据库系统的几个基本概念。 3.1.1 数据模型 所有的数据存储都依赖一个事先定义好的数据模型。以大家熟悉的 MySQL 举例，MySQL 是一种关系型数据库管理系统 (Relational DBMS) 。 MySQL 的数据模型是基于关系代数建立的，在 MySQL 中，所有的数据都从属于一个“表”，这个“表”可以与其他“表”进行关系代数运算。这就是一种非常典型的数据模型。 3.1.1.1 层级数据库 最早期的数据库大部分都是层级数据库 (Hierarchical Database)，在层级数据库中，所有的数据都是按照层级组织的。通常来说，这种类型的数据库中都有一个根结点，当用户需要寻找什么数据的时候，需要手动操作数据库，从根结点出发，定位到自己想要的数据。 举例来说，如果要存储书和作者的关系，可能看起来是下面这样： RECORD Author AuthorID: INTEGER Name: STRING Birthdate: DATE Books: SET OF Book RECORD Book BookID: INTEGER Title: STRING PublicationDate: DATE Author: REFERENCE TO Author // 定义作者 AUTHOR_1 = Author(AuthorID=1, Name=&quot;J.K. Rowling&quot;, Birthdate=&quot;31/07/1965&quot;) AUTHOR_2 = Author(AuthorID=2, Name=&quot;George Orwell&quot;, Birthdate=&quot;25/06/1903&quot;) // 定义书 BOOK_1 = Book(BookID=1, Title=&quot;Harry Potter and the Sorcerer&#39;s Stone&quot;, PublicationDate=&quot;26/06/1997&quot;, Author=AUTHOR_1) BOOK_2 = Book(BookID=2, Title=&quot;1984&quot;, PublicationDate=&quot;08/06/1949&quot;, Author=AUTHOR_2) // 通过这种方式将作者和书链接起来 AUTHOR_1.Books = [BOOK_1] AUTHOR_2.Books = [BOOK_2] // 查询的例子 // 找到所有AUTHOR_1写的书 for book in AUTHOR_1.Books: print(book.Title) // 获取BOOK_2的作者名 print(BOOK_2.Author.Name) 可以看到，在这种数据模型下，用户需要手动跟踪数据中存储的指针，直到找到自己的数据位置 1960 年代时，主要的数据库就是这种形式。这种形式的数据库中查询数据很复杂，和关系型数据库相比，不仅不能一次性使用外键连接多个表，而且查询数据的方式主要依赖代码实现，很难让用户单独使用命令查询。 在 1970 年代，随着关系代数的论文被发表，关系型数据库的概念开始兴起。我们今天所熟悉的 SQL 也被发明了。 IBM 的 System R 是第一个实现了关系代数模型的数据库产品。不过，由于当时的计算机尚未普及，对数据库系统系统的需求基本还停留在大型公司，其他大部分公司没有对数据库产品的需求。但 1970 年代的意义是重大的，因为关系型数据库这一时至今日仍然流行的数据模型就是在那时被确立的。 当然，尽管有了关系型数据库的雏形，当时的数据库系统还有很多基础研究没有完成。举例来说，对于数据库系统应该如何处理并发请求，如何管理锁来避免用户数据出现问题，直到 1990 年代才有系统性的论文出现。 随着计算机和互联网的普及，数据库系统不再是单纯的为大公司服务的昂贵系统，举例来说，1995 年微软发布了 Microsoft SQL Server ，这是一款能够运行在普通个人计算机上的数据库管理系统，而随着互联网的发展，越来越多的网站被建立起来，对数据库系统的需求激增，因此，以 MySQL 、MsSQL 、Postgres 等为代表的可以运行在普通个人计算机上的数据库系统从 1990 年代开始流行。 3.1.1.2 关系型数据库 在 1990 年代流行的数据库就是关系型数据库了，这个时候的数据库已经和今天大家熟悉的数据库很相似，我就不多做介绍。需要指出的是，今天大家很熟悉的 MySQL 在当时功能十分简单，是一个类似 KV数据库 的数据库。在 Innobase 将 innodb 捐献给 MySQL 之后， MySQL 才拥有了今天这些大家熟悉的功能。在 InnoDB 之前， MySQL 的默认存储引擎 MyISAM 不支持外键这种基本的关系型数据库功能，也不支持行锁这种基础的并发控制，是一个功能相对较弱的数据库。 3.1.1.3 NoSQL与NewSQL 在关系型数据库流行之后，随着互联网的进一步发展，对数据库系统也提出了新的要求，例如，非结构化数据存储，或者是大量数据的分区存储、分析能力，这些不是传统的关系型数据库能够支持的。因此，随后的数据库发展朝着两个方向进行： 第一个方向是发明各种新型的数据模型，例如文档数据库、图数据库，这些基于特定数据模型的数据库在特定的应用场景下相较关系型数据库有更大的优势。 第二个方向是进行数据库架构的演变，以支持不同的场景和灵活的性能要求，例如 Google 的 Spanner 就是典型的一种分布式、超大型数据库。 3.2 数据库系统的模块 不论数据库系统有哪些功能、实现哪种数据模型，在一些地方始终是相通的。本文介绍数据库系统通常的架构是什么样的。 我们来考虑一个基本的数据库系统，它至少包含以下两个部分： 用来处理用户请求的部分 用来管理数据存储的部分 通常，第一个部分被称为数据库系统的前端，而第二个部分被称为数据库系统的后端。 接下来， 我们分别考察这两个部分。 3.2.1 数据库的前端 3.2.1.1 查询解析器 这部分需要解析用户输入的命令，判断用户命令的合法性，举例来说： FELECT * FROM table1 LIMIT 0,10 这句 SQL 命令就不是一句合法的 SQL 命令，因为实际上不存在 FELECT 这一关键词 事实上，市面上的大部分数据库前端都会将用户输入的命令解析成抽象语法树 (AST) ，供后端处理，举例来说，下面是一颗解析 SQL 的 AST ： &lt;select-statement&gt; ├── &lt;column-list&gt; │ └── &lt;column-name&gt; │ └── name ├── &lt;table-name&gt; │ └── students └── &lt;condition&gt; ├── &lt;expression&gt; │ ├── &lt;MARK&gt; │ │ └── age │ ├── &lt;OP&gt; │ │ └── &gt; │ └── &lt;CONST&gt; │ └── &#39;18&#39; ├── &lt;logical-op&gt; │ └── AND └── &lt;expression&gt; ├── &lt;MARK&gt; │ └── gender ├── &lt;OP&gt; │ └── = └── &lt;CONST&gt; └── &#39;M&#39; 3.2.1.2 查询优化器 这部分做的事情主要是对用户输入的查询命令进行一个优化，需要注意的是，在数据库的后端实际上也存在执行计划的优化操作，这部分仅仅讨论的是对 AST 的优化操作。 例如，考虑这么一句 SQL ： SELECT * FROM table1 WHERE col1 &gt;= 10 AND col1 &lt;= 10 这句 SQL 实际上可以被等价优化成： SELECT * FROM table1 WHERE col1 = 10 这种基于 AST 的纯粹优化有很多好处，举例来说，如果不进行这样的优化，那么数据库后端在执行这个查询的时候大概率在执行的时候是这么执行的： 先找出所有满足 col1 &gt;= 10 或者 col1 &lt;= 10 的记录，然后检查是否满足其他条件。 这种查询显然是十分低效的，远不如根据 AST 优化后的结果。 3.2.2 数据库的后端 3.2.2.1 系统字典 数据库系统要对外维持自己的数据模型，就需要维护一些特定的信息。举例来说，如果是一个关系型的数据库，就需要维护自己目前库中有哪些表，表中有什么字段，哪些字段上存在索引这些信息。这一类的信息我们统称为数据库的多数据字典信息，属于是数据库系统自行维护的数据库元信息。数据库很大程度上需要依靠这些元信息来判断查询是否合法，以及如何执行查询。举例来说：当用户需要根据某一条件进行某一查询时，数据库需要根据元信息判断条件字段上是否存在索引，以此来决策具体的执行计划： SELECT * FROM table1 WHERE col1 = 10 对于这句查询语句，数据库系统就需要根据元信息来查询这么几个点： table1 是否存在 table1中有哪些字段 table1的数据存储在哪里 col1上是否有索引 3.2.2.2 查询计划器 查询计划器是所有数据库系统中最为复杂的部分，用于将逻辑上用户需要进行的查询计划转化为物理的执行计划，要明确到需要根据什么查数据，查什么数据，查到了数据之后进行怎么样的处理，具体的算子下沉还是上升等等问题，生成和优化物理执行计划本身是一个NP问题，这也是各个高性能数据库的技术核心。 在用户输入的命令被解析成 AST 并且通过数据字典的基本校验后，就进入到了查询计划器当中。 举例来说，考虑这么一条 SQL ： SELECT * FROM table1 WHERE col1 &gt;= 10 AND col2 &lt;= 10 这里其实有三条明显的执行路径： 直接扫描全部数据，然后根据条件筛选 根据索引拉出所有 col1 &gt;= 10 的数据，然后筛选满足 col2 &lt;= 10 的 根据索引拉出所有 col2&lt;=10 的数据，然后筛选满足 col1&gt;=10 的 哪个执行方案才是更优的呢？这就需要一些额外的信息辅助判断了： 例如，如果我们知道 col1&gt;=10 的数据只有大概 10 条，而 col2&lt;=10 的数据有 100000 条，那么显然第二个执行计划是更好的 反之，如果我们知道 col2&lt;=10 的数据明显少于 col1&gt;=10 的，那么显然第三个执行计划成本就更低 当然，如果说 col1 、col2 上不存在索引，或者说表的数据量很小，由于 id 在我们的数据库里是聚簇索引，不需要回盘查第二次，那可能直接拉所有的数据是更好的 3.2.2.3 事务管理器、锁管理器、并发控制器 这一部分，主要是大部分数据库都保有的、为了维持系统正确性、提供并发安全等而提供的机制，如果你的数据库要支持一些并发和隔离特性，那么需要一些额外的组件来支持数据库的正常工作。 这部分是一个比较复杂的问题，举例来说，对于以下2个同时执行的事务： SELECT * FROM table1 WHERE col1 = 10 FOR UPDATE SELECT * FROM table1 WHERE col2 = 10 FOR UPDATE SELECT * FROM table1 WHERE col1 = 10 FOR UPDATE SELECT * FROM table1 WHERE col2 = 10 FOR UPDATE 这 2 个事务就会出现互相等待对方释放锁的情况，进而造成死锁，这是不可接受的情况，需要有一个事务主动回滚，才能解决这一问题。 同样地，一些复杂的并发场景需要数据库系统主动识别才能避免问题发生，例如： SELECT id FROM table1 WHERE col1 = 10; -- 事务1，结果id=10 UPDATE table1 SET col1 = col1 + 10 WHERE col1 = 10; -- 事务2，提交 UPDATE table1 SET col1 = (10) + 10 WHERE id = 10; -- 事务1，提交 上述的问题就是一个明显的并发问题，事务1读取并使用过期的值来对数据进行更新。 由于这部分的内容相对比较复杂，要系统性的描述需要比较大的篇幅，在之后的内容中会进一步进行讨论。目前仅仅讨论到存在的问题和需要引入解决这些问题的组件。 3.2.2.4 缓存池 当执行计划被确定之后，就会对硬盘进行大量的 io操作 ，理论上，这些 io操作 很可能是随机的，至少也是随机混合的，这一类的读写模式对硬盘不友好，而实际上，即使这种模式对硬盘是友好的，硬盘的数据读取时间对于 CPU 来说也是十分漫长的。 图 3.1: 各种介质的延迟 图源 https://blog.bytebytego.com/p/ep22-latency-numbers-you-should-know 因此，所有的io操作最好是在内存中进行，由缓存池负责对硬盘的实际io读写调度 3.2.2.5 索引 数据库系统大量需要索引来辅助查找和存储数据，如果没有索引的帮助，数据库系统每次查找数据时只能对所有数据进行遍历，这是不可接受的。而目前常见的两种用于在硬盘数据上建立索引算法是 B树 (包括 B+树 等各种衍生)和 SSTable 。这些算法不仅是要尽可能高校地满足各类查询和插入需求，更重要的是要能够契合硬盘的硬件特性，尽可能减少读取硬盘的次数，一次尽可能多的读取数据而不是多次读取少量数据。 3.2.2.6 物理文件管理器 最后我们要提到的是物理文件管理模块，这里的模块负责的是硬盘空间的管理，这也是一个相对来说有一些复杂的问题。 举例来说，考虑我们需要向数据库存储一份数据，这份数据长 1000 个字节，那么存储引擎就需要考虑几个问题： 在哪里存这份数据？空间如何分配？ 如果有数据最近被删除了，怎么回收之前的数据供使用？ 怎么样存储数据才能尽可能提高查询效率？ 这些问题一定程度上也决定了数据库的性能表现 以上是对数据库系统各个常见模块的一些介绍，这些内容对理解接下来的行文思路会有很大帮助。 "],["query-language.html", "第 4 章 查询语言 4.1 数据模型与查询语言 4.2 定义自己的简单类SQL语言 4.3 实现一个简单SQL解析器", " 第 4 章 查询语言 4.1 数据模型与查询语言 要设计一个数据库系统，第一步就是设计其对外的接口——外界要如何操作数据库中的数据，如何查找数据？ 要解决这个问题，首先要定义一种数据模型。 数据模型主要包括两个部分：其一，其定义了数据在数据库中的逻辑表示，其二，其定义了外界操作数据的法则。 数据模型的意义在于，通过定义一套数据模型，我们可以用指定的语言描述我们想要的数据，剩下的工作就全部可以交给数据库系统进行，而不用我们关心。 图 4.1: 查询语言 历史上，有非常多的数据模型，在此，我简单介绍几种。 4.1.1 层次(Hierarchical model)模型 在层次模型里，数据是通过类似树的形式组织的。 IBM 的 IMS 最先使用的是层级模型，IBM 为之开发了一种独特的数据查询语言，名为 DL/I (Data Language/One)。 下面是几个 DL/I 的例子： GET CUSTOMERS BY NAME = &#39;SMITH&#39; GIVE ADDRESS PHONE 在这里，GET 是 DL/I 的关键词，它表示要从 CUSTOMERS 这一数据集中获取数据。 BY 在这里也是一个关键词，表示要使用的筛选条件，最后，GIVE 关键词表示返回的数据中仅需要 ADDRESS 和 PHONE 这两个字段。 上面这个例子还不能很好地说明数据的层次结构，下面这个例子能够更好地说明这一点： 考虑你需要获取所有状态为 PENDING 的订单号和它对应的顾客姓名，你可以使用下面的语句： GET ORDERS BY STATUS = &#39;PENDING&#39; GIVE ORDER-ID CUSTOMER-NAME 通过上面两个例子，你应该可以发现，在 DL/I 中，数据是按照一棵树的形式展开的，ORDERS 表的结构大致如下： ORDERS ORDER-ID (integer) CUSTOMER-NAME (string) STATUS (string) 而 CUSTOMER 则是上文中我们提到的另一个表： CUSTOMERS NAME (string) ADDRESS (string) PHONE (string) 尽管在查询时通过这种方式来处理一对多关系非常便利，但由于其表示多对多关系时存在困难，且维护记录与记录的关系十分麻烦（记录与记录之间通过类似指针的方式关联，因此在更新时需要考虑非常多的内容），这种数据模型在70年代后逐渐被关系模型和 SQL 取代。 4.1.2 关系模型 关系模型是非常重要的模型，时至今日，关系模型及其衍生物 SQL 依然非常流行。 关系模型最初是在 A relational model of data for large shared data banks 这篇论文中由 IBM研究院 在 70 年代提出的，一个数据模型具有如此长久的生命力是非常不可思议的，恰恰说明了关系模型真的解决了之前的诸多问题。 在这篇文章中，作者首先指出了当时存在的层次模型与网络模型的诸多缺点，并提出了关系模型希望取而代之。有兴趣的读者可以进行阅读。上述模型的最重要缺陷之一是由于其对用户暴露了过多数据存储的细节(指针)，进而引入了极大的编程复杂性，因此，关系模型在设计之初的核心思想就是这是一个声明式的模型，不会把关于数据存储的详细信息暴露给用户。 关系模型中，定义了 关系(relations) 和对 关系 的一系列 操作(operations) ，这些简单的操作可以叠加，从而形成复杂的关系表达能力。 3 个基本的关系操作是： 选择操作，可以选择关系中符合对应条件的记录。例如，以下表达式可以选择 Employees 中所有 Salary 大于 50000 的记录。 σ Salary &gt; 50000 (Employees) 投影操作: 投影操作可以从关系集合中选择一部分列。 例如，下面的表达式可以表示从 Employees 数据集中选择记录的 Name 和 Salary 字段。 π Name, Salary (Employees) 连接: 连接操作可以将 2 个关系集合并成一个，通过指定连接字段，可以将拥有相同连接字段值的关系联合起来。例如，下面的表达式可以将 Employees 和 Departments 这 2 个关系通过 DepartmentID 连接起来。 Employees ⨝ DepartmentID = DepartmentID (Departments) 4.1.2.1 SQL SQL 是随着关系模型被提出的，SQL是自然语言化的关系代数表达式。例如，上面的 3 个关系代数表达式对应的 SQL 语句分别是: SELECT * FROM Employees WHERE Salary &gt; 50000; SELECT Name, Salary FROM Employees; SELECT * FROM Employees INNER JOIN Departments ON Employees.DepartmentID = Departments.DepartmentID; 4.1.3 文档模型 最后，在结束之前，再介绍一种随着 noSQL (Not Only SQL)发展普遍被使用的模型——文档模型。 在一个文档模型的数据库中，你可以认为是一个 数据库(bucket) 中保存了 n 个 JSON ，一个数据库是一个 JSON 的 桶(bucket) ，每个 JSON 就是一条记录。这些 JSON 之间不需要有相同的结构，对 JSON 的大小等都没有限制。 与文档模型相比，关系模型要求一切都被定义好，所有的关系都必须预先定义好自己的 schema(列和列的类型) ，如果没有预先定义，那么这个列就无法被搜索和单独访问。然而，随着计算机软件的发展，出现了一些并不适合预先定义好 schema 的数据，另外，文档模型由于是一个 非归一化(denormalized) 的模型，记录与记录之间不会互相依赖，只需要保证单个文档的准确性，也不需要支持传统关系型数据库那样多个表之间的事务保证，在分布式部署等方面具有原生的优势，通常更益于并行计算，能够获得更大的性能收益。 4.1.3.1 层次模型与文档模型的比较 读者可能会觉得文档模型与层次模型有不少相似之处，尤其是他们可以不加限制地嵌套记录这一点。 确实，层次模型看起来与文档模型有非常多的相似之处，但其中最重要的区别在于，层次模型依然存在记录与记录的关联关系——层次模型不保存非归一化的记录，而是保存指针。这种设计导致了层次模型的失败——维护这些关系过于复杂，经常把系统搞得一团乱麻。相比之下，文档模型舍弃了指针设计，不允许文档之间互相关联，这种功能上的牺牲极大降低了数据模型的复杂性。因此，文档模型不会走层次模型的老路。 4.2 定义自己的简单类SQL语言 SQL，即 Structured Query Language ，具有比较强的表达能力，最早在1979年由 Oracle 推向商用数据库市场。 随着关系型数据库的流行， SQL 的影响力日渐庞大，几乎所有的关系型数据库，甚至部分 KV数据库 、 列数据库 也支持 SQL 或 SQL方言 作为数据查询语言和操作语言。 接下来，为了实现我们自己的数据库，我们也需要为我们的数据库选择一种用于操作数据和查询数据的语言。这里，我选择了一种简化的 SQL 语言。这篇文章主要介绍如何定义这种语言。 4.2.1 一点点的编译原理小知识 首先，不妨思考这个问题：如何定义一句 SQL 语句是否合理？如何设计我们自己的 SQL 语法？ 一个答案是使用 BNF范式（巴科斯范式）。 在解析一句 SQL 语句是否合法时，主要包括以下三个步骤。 第一步，词法分析，这一步中，我们会把用户输入的 SQL 语句分为一个个的 token ，每个 token 都是 BNF 中定义的关键词。 第二步，语法分析，在这一步，我们分析 token 的排列规则是否符合预先设定的规则，也就是是否符合我们定义的 BNF范式 的要求。经过语法分析后，我们能得到一些结构化的数据，这些结构对应的就是 SQL 语句的解析结果。比较典型的结构体是 Parse Tree 或者 AST (抽象语法树)。 第三步，语义分析，这一步中我们要分析已经确定符合 BNF范式 的语句是否存在语义上的缺陷，例如，是否在字符串类型的字段中插入了数字，等等。 下面，我会给一些简单的例子来介绍上面的步骤，并最终给出我们的 SQL 语句 BNF 。 4.2.2 词法分析 例如，我们有这样一条 SQL 语句: SELECT name FROM students WHERE age &gt; '18'; 在 词法分析 阶段，我们将该语句分解为以下 token : SELECT , name , FROM , students , WHERE , age , &gt; ,'18' , ; 相信你也明白所谓的 词法分析 的作用了，在这一步中，我们定义一系列规则，来明确在我们定义的语言中什么样的字符可以连接在一起构成一个 token ，什么样的字符自己就是一个 token ，而什么样的字符是非法的。 具体来说，怎么定义 token 呢？接下来是定义 token 的方法 4.2.2.1 Token的定义 关键词 诸如 SELECT 、 WHERE 这一类的 token 是我们预先定义好的关键词，这类关键词是可以枚举的 比较符 诸如 &gt; 这样的字符，自己就可以成为一个单独的 token ，这一类情况和关键词类似，记为 OP 标识符 像是name, students 这些本身都不属于我们语法的一部分，是根据用户所指定的表而变化的，这部分的数据我们可以统称为 标识符 ，记为 MARK 常量 虽然上面的 SQL 语句中没有，但我们不难想到，被引号包裹的，里面的内容，不论是不是连续的，中间有没有空格，都是常量，记为 CONST 4.2.2.2 词法分析结果 最后，在定义了上面这些 token 之后，展示 词法分析 的具体结果 从形式上来说，SELECT name FROM students WHERE age &gt; 18; 可以解析成： &lt;SELECT&gt;, &lt;MARK&gt;, &lt;FROM&gt;, &lt;MARK&gt;, &lt;WHERE&gt;, &lt;MARK&gt;, &lt;OP&gt;, &lt;CONST&gt;, &lt;END&gt; 而具体来说，每一个形式上的 token 都对应一个具体的值，也就是这样的结果： SELECT, name, FROM, students, WHERE, age, &gt;, 18, ; 4.2.3 语法分析 有了 词法分析 的结果，就可以在此基础上进行 语法分析 。语法分析 的目的是检查 token 连在一起后是不是能符合我们定义的语法 ，并解析生成 抽象语法树 4.2.3.1 BNF范式的例子 在根据 BNF范式 来解析用户输入时，通常先认为用户输入的内容都属于第一条 BNF范式 ， 随后根据具体情况根据右边的表达式展开即可。 &lt;select-statement&gt; ::= SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt;; &lt;column-list&gt; ::= &lt;column-name&gt; | &lt;column-name&gt;, &lt;column-list&gt; &lt;column-name&gt; ::= &lt;MARK&gt; &lt;table-name&gt; ::= &lt;MARK&gt; &lt;MARK&gt; ::= &lt;letter&gt; {&lt;letter-or-digit&gt;} &lt;CONST&gt; ::= &#39;&lt;MARK&gt;&#39; &lt;OP&gt; ::= &lt; | = | &gt; | &lt;= | &gt;= | != &lt;letter&gt; ::= a | b | c | ... | z | A | B | C | ... | Z &lt;letter-or-digit&gt; ::= &lt;letter&gt; | &lt;digit&gt; &lt;digit&gt; ::= 0 | 1 | 2 | ... | 9 上面是一个很简单的 BNF 例子，这个例子可以解析上面给出的 SQL 语句 当然了，它也有不少不足，举例来说，上面我们给出的 BNF范式 只能解析含有一个 WHERE 条件的 SELECT 语句， BNF 是表现力很强的语言，我们可以稍作修改，让我们定义的 SELECT 语句支持任意多个 WHERE 条件： &lt;select-statement&gt; ::= SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;condition&gt; &lt;column-list&gt; ::= &lt;column-name&gt; | &lt;column-list&gt;, &lt;column-name&gt; &lt;column-name&gt; ::= &lt;MARK&gt; &lt;table-name&gt; ::= &lt;MARK&gt; &lt;condition&gt; ::= &lt;expression&gt; | &lt;condition&gt; &lt;logical-op&gt; &lt;expression&gt; &lt;expression&gt; ::= &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt; &lt;logical-op&gt; ::= AND | OR &lt;OP&gt; ::= &quot;=&quot; | &quot;&lt;&quot; | &quot;&gt;&quot; | &quot;&lt;=&quot; | &quot;&gt;=&quot; | &quot;!=&quot; &lt;MARK&gt; ::= &lt;letter&gt; {&lt;letter-or-digit&gt;} &lt;CONST&gt; ::= &#39;&lt;string&gt;&#39; &lt;string&gt; ::= {&lt;letter-or-digit&gt;} &lt;letter&gt; ::= a | b | c | ... | z | A | B | C | ... | Z &lt;letter-or-digit&gt; ::= &lt;letter&gt; | &lt;digit&gt; &lt;digit&gt; ::= 0 | 1 | 2 | ... | 9 上面的例子里给出了一个支持任意多个 WHERE 条件的 SELECT 语句的 BNF范式 在这篇文章中，我暂时不会给出 BNF范式 应该如何解读的例子，希望读者反复研读上面给出的 2 则例子，对 BNF范式 建立一个大概的印象和理解。 如果读者阅读 BNF范式 时发现很难完全理解 BNF范式 的意义，在下一篇文章中会有如何根据 BNF范式 编写程序、解析出 AST 的内容，可以参阅那部分的内容。 4.2.3.2 根据BNF范式来进行语法解析 仅仅给出 BNF范式 的方式，对没有编译原理基础的读者可能不友好，读者可能不知道应该如何利用 BNF范式 来解析语句，但在这节内容中，我们仅仅强调 BNF范式 定义的语法可以将用户输入的 SQL语句 解析为 AST。 下面，我们做一个将 SELECT 语句最后解析成 AST 的例子： 考虑下面的 SQL 语句：SELECT name FROM students WHERE age &gt; '18' AND gender = 'M'; 在完成基本的词法分析，将 SQL语句 转化成 token 后，就可以根据 BNF范式 得到以下的 抽象语法树 ： &lt;select-statement&gt; ├── &lt;column-list&gt; │ └── &lt;column-name&gt; │ └── name ├── &lt;table-name&gt; │ └── students └── &lt;condition&gt; ├── &lt;expression&gt; │ ├── &lt;MARK&gt; │ │ └── age │ ├── &lt;OP&gt; │ │ └── &gt; │ └── &lt;CONST&gt; │ └── &#39;18&#39; ├── &lt;logical-op&gt; │ └── AND └── &lt;expression&gt; ├── &lt;MARK&gt; │ └── gender ├── &lt;OP&gt; │ └── = └── &lt;CONST&gt; └── &#39;M&#39; 读者可以发现，AST树 中的所有 叶子结点 都是 BNF范式 中定义的不可继续展开(称为终止符)的，而 AST树 的 根节点 则是第一条 BNF范式。 关于如何根据 BNF 来直接解析出上面这颗 AST 的算法，在本篇文章中暂时不涉及，会在之后的篇幅中给简单介绍。 4.2.4 语义分析 在有了 AST 的基础上，可以对 AST 进行 语义分析 ，发现 AST 中符合文法逻辑，但不符合逻辑的地方。 例如，name 字段 不存在，students 这一 表 不存在，或者是age 字段 明明是数字类型，比较的值却是字符串，这一类简单的问题都可以通过语义分析来发现。 4.3 实现一个简单SQL解析器 4.3.1 自顶向下的语法解析器 让我们回忆之前提到过的可以描述 SELECT 语句的 BNF范式 ： &lt;select-statement&gt; ::= SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt;; &lt;column-list&gt; ::= &lt;column-name&gt; | &lt;column-name&gt;, &lt;column-list&gt; &lt;column-name&gt; ::= &lt;MARK&gt; &lt;table-name&gt; ::= &lt;MARK&gt; &lt;MARK&gt; ::= &lt;letter&gt; {&lt;letter-or-digit&gt;} &lt;CONST&gt; ::= &#39;&lt;MARK&gt;&#39; &lt;OP&gt; ::= &lt; | = | &gt; | &lt;= | &gt;= | != &lt;letter&gt; ::= a | b | c | ... | z | A | B | C | ... | Z &lt;letter-or-digit&gt; ::= &lt;letter&gt; | &lt;digit&gt; &lt;digit&gt; ::= 0 | 1 | 2 | ... | 9 在这篇文章中，我会一步一步介绍如何使用自顶向下的解析方式来根据 BNF范式 解析这句 SQL ： SELECT name FROM students WHERE age &gt; &#39;18&#39;; 4.3.2 BNF范式的基本概念 我们首先来回顾一下 BNF范式 ，以这条 BNF范式 为例： &lt;select-statement&gt; ::= SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt;; 在这句 BNF范式 的左侧，是一个名为 &lt;select-statement&gt; 的 非终止符 在 BNF范式 的右侧，是SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt;;，这是一个 终止符 与 非终止符 混合的 展开式 。 其中，SELECT、FROM、WHERE、; 是 终止符 ，而 &lt;column-list&gt; &lt;table-name&gt; &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt; 是 非终止符 。 从这些描述中你可以发现，所谓的终止符就是常量，是不可以再向外推导的内容，而非终止符则有其他的 BNF范式 可以继续进行推导。 而在根据 BNF范式 推导用户输入生成 AST 时，我们总有一个起始的状态，在这里 &lt;select-statement&gt; 就是我们的起始状态。 4.3.3 根据BNF范式生成AST的过程 接下来，我以这句 SQL 为例，演示如何根据 BNF范式 、自顶向下的解析方法来生成 AST ： SELECT name FROM students WHERE age &gt; &#39;18&#39;; 4.3.3.1 生成token 不难发现，在进行了简单的 词法分析 后，上面的 SQL 语句可以解析为下面的这些 token ： SELECT (name) FROM (students) WHERE (age) (&gt;) (‘18’) 4.3.3.2 自顶向下解析 接下来，可以根据 BNF 进行解析，从最顶端的 非终止符 &lt;select-statement&gt;开始，尝试将输入的 token 匹配到这个 BNF范式 。 SELECT 是 终止符 ，它与输入的第一个 token 匹配，因此消耗这个 token 。 下一个是 &lt;column-list&gt; ，由于 BNF范式 中存在 &lt;column-list&gt; ::= &lt;column-name&gt; | &lt;column-name&gt;, &lt;column-list&gt; ，它可以继续扩展为 &lt;column-name&gt; ，又可以继续展开为 &lt;MARK&gt; 。这里 &lt;MARK&gt; 可以进一步扩展为 &lt;letter&gt; {&lt;letter-or-digit&gt;} 。在这个例子中，name 与这个模式匹配，所以消耗 token name。 下一个 终止符 是 FROM ，与输入的下一个 token 匹配，所以消耗 token FROM。 接着是 &lt;table-name&gt; 。我们的输入 token 是 &lt;letter-or-digit&gt;(students) ，它可以匹配为 &lt;table-name&gt; 中的 &lt;MARK&gt; 。此时，students 匹配 &lt;letter&gt; {&lt;letter-or-digit&gt;}，因此消耗 token students。 接下来的 终止符 WHERE 与输入的 token 匹配，所以消耗 token WHERE 。 下一个 非终止符 是 &lt;MARK&gt;，与输入的 token &lt;MARK&gt;(age) 匹配，所以消耗 token age。 下一个 终止符 &lt;OP&gt; 与输入的 token &lt;OP&gt;(&gt;) 匹配，所以消耗 token &gt;。 最后，&lt;CONST&gt; 与输入的 token &lt;CONST&gt;('18') 匹配，所以消耗token '18'。 以上，我们成功地使用 BNF范式 和 自顶向下的解析方法 ，将给定的 SQL 语句解析为一系列的 token ，并与 BNF范式 进行匹配。 4.3.3.3 生成AST（抽象语法树） 基于上述的解析过程，你可以发现，我们从第一条 BNF范式 出发，通过递归下降的方式直到我们将所有的 token 都推导为 终止符 ，而从这个推导的过程，我们可以构建一个简化的 AST ： &lt;select-statement&gt; | |-- SELECT | |-- &lt;column-list&gt; | | | |-- &lt;column-name&gt; | | | |-- name | |-- FROM | |-- &lt;table-name&gt; | | | |-- students | |-- WHERE | |-- &lt;condition&gt; | |-- &lt;MARK&gt; | | | |-- age | |-- &lt;OP&gt; | | | |-- &gt; | |-- &lt;CONST&gt; | |-- &#39;18&#39; 这样，通过自顶向下的解析方法和 BNF范式 ，我们将一个 SELECT 语句转化为了 AST ，方便之后的 语义分析 和 代码生成。 4.3.3.4 用Python实现自顶向下解析Demo 上述的过程已经很容易理解，但为了进一步明确，我把解析的过程用 python 代码实现了一下。有需要的读者可以把代码和上面的解析过程进行对照： class Node: def __init__(self, value): self.value = value self.children = [] def add_child(self, child): self.children.append(child) def __repr__(self, level=0): ret = &quot;\\t&quot; * level + repr(self.value) + &quot;\\n&quot; for child in self.children: ret += child.__repr__(level + 1) return ret def parse(tokens): current_token_index = 0 def consume(expected): nonlocal current_token_index if tokens[current_token_index] == expected: current_token_index += 1 return True return False def parse_mark(): nonlocal current_token_index node = Node(tokens[current_token_index]) current_token_index += 1 return node def parse_op(): nonlocal current_token_index node = Node(tokens[current_token_index]) current_token_index += 1 return node def parse_const(): nonlocal current_token_index node = Node(tokens[current_token_index]) current_token_index += 1 return node def parse_column_list(): node = Node(&#39;column-list&#39;) while True: node.add_child(parse_mark()) if not consume(&#39;,&#39;): break return node def parse_table_name(): node = Node(&#39;table-name&#39;) node.add_child(parse_mark()) return node def parse_where(): node = Node(&#39;Where&#39;) mark = Node(&#39;Mark&#39;) mark.add_child(parse_mark()) op = Node(&#39;OP&#39;) op.add_child(parse_op()) const = Node(&#39;Const&#39;) const.add_child(parse_const()) node.add_child(mark) node.add_child(op) node.add_child(const) return node def parse_select_statement(): # 解析入口 root = Node(&#39;select-statement&#39;) if not consume(&#39;SELECT&#39;): raise ValueError(&quot;Expected &#39;SELECT&#39;&quot;) root.add_child(parse_column_list()) if not consume(&#39;FROM&#39;): raise ValueError(&quot;Expected &#39;FROM&#39;&quot;) root.add_child(parse_table_name()) if not consume(&#39;WHERE&#39;): raise ValueError(&quot;Expected &#39;WHERE&#39;&quot;) root.add_child(parse_where()) return root return parse_select_statement() # 已经分好的token tokens = [&#39;SELECT&#39;, &#39;name&#39;, &#39;FROM&#39;, &#39;students&#39;, &#39;WHERE&#39;, &#39;age&#39;, &#39;&gt;&#39;, &quot;&#39;18&#39;&quot;] # 自顶向下解析 ast = parse(tokens) print(ast) 上面的 python 代码完全复现了之前描述的自顶向下解析过程，根据 词法分析 的结果解析出了一颗 抽象语法树 ，下面是运行的结果： &#39;select-statement&#39; &#39;column-list&#39; &#39;name&#39; &#39;table-name&#39; &#39;students&#39; &#39;Where&#39; &#39;Mark&#39; &#39;age&#39; &#39;OP&#39; &#39;&gt;&#39; &#39;Const&#39; &quot;&#39;18&#39;&quot; 4.3.4 LL(1)解析器 需要指出，编译原理其实是相对复杂的，这里我们使用的 语法分析 方式只是所有语法分析方式中最简单的一种。 具体来说，我们的解析方式总是从左至右解析，并且总是只预读1个 Token ，这样的解析方式被称为 LL(1) ，我们实现的解析器是一个 LL(1) 解析器。 这种方式有它的局限性，例如，它不能处理含有左递归的语法规则，不能处理需要预读 1 个以上 Token 的复杂语法，并且，和自顶向下解析相对应地，也存在自底向上的解析方式，事实上，自底向上的解析方式更能够适应复杂的文法，在业界被广泛使用。 "],["intro-to-store.html", "第 5 章 存储基础 5.1 硬盘与操作系统 5.2 机械硬盘特性与文件缓存 5.3 SSD特性与随机读写性能 5.4 文件系统", " 第 5 章 存储基础 5.1 硬盘与操作系统 大家都知道数据是存储在硬盘上的，这篇文章会重点讨论硬盘与操作系统是如何交互的，这部分的讨论侧重于软件的讨论，硬盘还有一些值得注意的硬件特性，例如高延迟、随机读写性能差、读写放大等特性，会在另外的文章中讨论。 5.1.1 操作系统如何认识硬盘 目前，硬盘已经有多种不同的物理接口，消费级硬件中主流的是 SATA 和 NGFF (M.2) 接口的硬盘，SATA 接口的硬盘几乎一定默认使用 AHCI 协议与操作系统进行交互，而 NGFF 接口的硬盘可能会存在支持 AHCI 和 NVMe 两种不同协议的硬盘，彼此之间不互相兼容。 本文要讨论的是操作系统与硬件交互的标准方式，也就是类似软件上接口(interface)的概念，因此本文主要讨论的是AHCI或者NVMe，而不是SATA或者NGFF。 5.1.2 操作系统对硬盘的抽象 以 AHCI 协议为例，AHCI 协议是 Intel 牵头制定的，官方有详细的协议规范： https://www.intel.com/content/www/us/en/io/serial-ata/serial-ata-ahci-spec-rev1-3-1.html 这份规范是非常底层的，直接说明了操作系统与硬件如何交互： 图 5.1: 规范中对数据FIS传输的说明 抽象来说，AHCI 包括了一些命令，操作系统可以通过操作内存来调用这些命令，下面是我抽象的几个指令： 指令 作用 Read Sector 用来读取一个或者多个扇区的数据 Write Sector 用来写入一个或者多个扇区的数据 Identify Device 获取设备描述信息 Flush Cache 强制硬盘将缓存中的数据写入到盘上 Standby Immediate 提示硬盘从待机状态恢复到工作状态 Idle Immediate 提示硬盘从工作状态切换到低功耗待机模式 Data Set Management 用来提示硬盘进行TRIM等操作（SSD和Host managed SMR盘常用） Read FPDMA Queued 将一个读取指令加入到硬盘本地的队列中，硬盘可以乱序执行队列中的指令来获得最佳性能 Write FPDMA Queued 将一个写入指令加入到硬盘本地的队列中，硬盘可以乱序执行队列中的指令来获得最佳性能 其中的很多指令都很容易理解，例如Read Sector，就是读取数据的指令，Idle Immediate 是对硬盘电源状态进行管理的指令，我想，读者可能会对Data Set Management 这一指令的作用有些困惑，这里就对这个做一下展开解释。 SSD 和 Host-Managed SMR 硬盘有一个特性：在写入数据前必须先擦除掉这部分的数据，而擦除需要花费不少时间。因此，操作系统可以通过这些指令在文件删除时就通知 SSD：这片区域不再使用了，SSD 就会在空闲时进行擦除操作，节省下次写入时需要的时间。这种操作可以认为是一种垃圾回收过程，不过需要注意其与内存管理中的垃圾回收有明显区别。 除了对 AHCI 的底层命令进行抽象封装外，操作系统还进行了一系列额外的工作，这部分工作视操作系统的不同而不同。例如，在 Linux 系统中，所有的硬盘都被抽象为块设备： # lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 20G 0 disk ├─sda1 8:1 0 476M 0 part /boot └─sda2 8:2 0 19.5G 0 part / 通过上面的命令可以看出，在这台系统上有 20G 的硬盘，这块硬盘分为 2 个分区，被 Linux 系统识别为sda的块设备。 下一节，我们简单聊一聊 Linux 系统中的“块设备”的特性和使用方法。 5.1.3 块设备(Block device) 为什么 Linux 系统将硬盘抽象成块设备？块设备是什么含义？ 块设备在 Linux 系统上是指能够按照固定大小的块进行数据存取的设备，例如，对于扇区大小是 512B 的硬盘来说，块的大小就是 512B ，在 Linux 系统上，下面所有的设备都是块设备： 设备名称 设备类型 /dev/sdX AHCI设备 /dev/sr0 光驱 /dev/hdX IDE设备 /dev/nvmeX NVMe设备 /dev/mmcblkX MMC设备(eMMC或者SD卡) 在 Unix 系统中，一切都是文件，因此，块设备作为文件也实现了文件的基本接口，可以被标准的文件 API 读取和写入： # sudo head -c 8 /dev/sda ?c??м# 以上的命令使用 head 工具读取了硬盘最开始的 8 个字节的数据，当然了，展示出来的是乱码，因为这些二进制数据不是用 ASCII 编码的。 5.2 机械硬盘特性与文件缓存 在上一节，我们聊了硬盘与系统交互的标准接口，但没有涉及到硬盘的硬件特性。在这一节，我们简单讨论一下硬盘的一些基本硬件特性，以及操作系统对这些硬件特性所做的优化工作。 5.2.1 最小读写单位 磁盘在经过操作系统的封装后，对用户来说有和内存几乎相同的读写方式。就像内存是一个大数组一样，磁盘本身也被“块” (Block) 这一概念分割，对于磁盘来说，一个“块”的大小通常是 512B (机械硬盘和大部分 SSD )~4K (少量新款 SSD 系统)，在访问磁盘数据的时候，也是通过 Offset 的方式来访问，你告诉硬盘需要第 4 页(从 0 开始)，那么硬盘就会把第 2048~2560Byte 的数据给你。 硬盘的块大小可以通过smartctl工具获得 # smartctl -a /dev/nvme0n1 smartctl 7.2 2020-12-30 r5155 [x86_64-linux-5.15.0-58-generic] (local build) Copyright (C) 2002-20, Bruce Allen, Christian Franke, www.smartmontools.org === START OF INFORMATION SECTION === Model Number: INTEL SSDPEKKF010T8L Serial Number: PHHH843401491P0E Firmware Version: L08P PCI Vendor/Subsystem ID: 0x8086 IEEE OUI Identifier: 0x5cd2e4 Controller ID: 1 NVMe Version: 1.3 Number of Namespaces: 1 Namespace 1 Size/Capacity: 1,024,209,543,168 [1.02 TB] Namespace 1 Formatted LBA Size: 512 Namespace 1 IEEE EUI-64: 5cd2e4 2591417dab Local Time is: Wed Jan 25 07:44:23 2023 UTC Firmware Updates (0x14): 2 Slots, no Reset required Optional Admin Commands (0x0017): Security Format Frmw_DL Self_Test Optional NVM Commands (0x005f): Comp Wr_Unc DS_Mngmt Wr_Zero Sav/Sel_Feat Timestmp Log Page Attributes (0x0f): S/H_per_NS Cmd_Eff_Lg Ext_Get_Lg Telmtry_Lg Maximum Data Transfer Size: 64 Pages Warning Comp. Temp. Threshold: 75 Celsius Critical Comp. Temp. Threshold: 80 Celsius ... 可以看到，这块硬盘的块大小是 512 Byte。 这样的地址在OS中称为 LBA (Logical Block Address) ，当然，实际 上LBA 之所以是 Logical Address 的是因为他并不像内存那样具备实际意义。 在机械硬盘上，LBA 会被硬盘转换为 CHS 格式 (第C磁盘第H柱面第S扇区，我从网上找了一张示意图) ，在现代的 SSD 上，LBA 与闪存的 Block 或者 Page 亦无固定的对应关系，是在运行时由硬盘的固件动态分配的。 图 5.2: CHS与扇区的对应关系 5.2.2 分区 人们为了 提高机械硬盘的性能 ， 会把硬盘分为多个区。外圈的硬盘速度比内圈慢，而扇区号从小到大对应的是从硬盘的外圈到硬盘的内圈，因此系统装在开始的分区能够获得更好的性能 。（在 SSD 上，分区对性能没有什么帮助） 所谓分区就像我们在一个分区内创建了一个个文件一样，也是在一块连续空间上由元数据记录、划分的一块块空间，在以前，分区表的格式叫 MBR ，由于 MBR 是 90 年代的产物，存在诸多如最大分区大小的限制，后续由 GPT 取代。关于 MBR 和 GPT 并没有太多与我们相关的细节需要了解，我们只需要知道这些是规定了分区起始位置和结束为止的元数据即可。如果你对这块内容有更多兴趣，可以参阅：MBR与GPT 5.2.3 使用整个分区作为数据库文件的好处 说了这么多，终于可以聊一些和数据库有关的话题了。 在 Oracle 数据库中，用户是可以选择一整个分区给数据库使用的。为什么 Oracle 要用这种方式来管理数据，而不是单纯使用一个文件呢？要知道，文件比分区更容易保存、备份，倘若空间不够用，要给文件扩容时，也只需要把文件复制进一个更大的分区，而不是像分区一样来回调整分区表和修正分区数据。在维护便利性上，文件是比分区更好的，尽管如此，为什么 Oracle 还是提供了使用分区的选项呢？ 答案很简单，因为 Oracle 想要排除 OS 的一切影响。 OS 提供的文件管理机制并不适合数据库使用，举例来说，大部分的 OS 都会对文件进行预读操作，但遗憾的是 OS 并不理解数据库的文件结构，按照简单的顺序预读也许只会造成资源的浪费。OS 为什么要进行预读操作呢？这与硬盘的特性息息相关，因为硬盘本身的访问速度慢，带宽低，而大部分对硬盘数据的读写都遵循数据局部性，也就是经常需要被一起访问的数据通常都存在相邻的地方。 5.2.4 Linux如何加速文件的读写 以 Linux 为例，简单介绍一下 OS 为了加速文件读写都会做些什么。 需要注意，下面的部分说法是不准确的，只能给你一个大概的蓝图，如果你对具体的细节更有兴趣，应该阅读其他拓展材料。 补充一个我记忆中的趣事，Windows 在 Windows XP 开始引入了一个名为 Prefetch 的服务，这个服务的作用是在启动程序前进行劫持动作，由 OS 判断程序是否经常读取某些文件，如果发现程序经常读取某些特定文件，就会在启动程序前尝试将特定文件加载到内存中，通过这种方式来加快程序之后的运行速度。 类似的机制在 Windows Vista 中进化为了一个名叫 SuperFetch 的服务，微软官方似乎并没有仔细介绍工作原理的文档，但可以肯定 Superfetch 比 Prefetch 用了更激进的、主动式的预读策略，以至于那个年代的 Windows 经常把用户2-4G的内存占满，引起了用户(特别是中国，因为某些特殊原因中国用户有看自己还剩多少内存的习惯)的强烈不满。 由于 Windows 的文档实在匮乏，我也不了解 Windows 的细节，上面的 Windows 的例子只是为了让读者对预读的重要性有一个基本的认知。接下来以 Linux 为例介绍 OS 对文件的预读操作。 在开始介绍之前，我会先罗列一些 Linux 缓存文件的基础概念。 原则上，除非在挂载文件系统时或者用户要求，所有的读写请求均会经过磁盘缓存 用户在写入文件时，文件会被先写进内存中，在内存中被称为 Dirty Page ，需要等待内核在内核认为合适的时机或者用户手动执行 fsync 命令时同步到硬盘 读取文件时也是同理，系统会首先判断当前要读取的部分在不在 Page Cache 中，如果命中就直接使用 Linux 系统根据局部性原理会对文件进行预读，并不是你请求哪些它就会读哪些到内存中 如果应用程序修改了文件的一个部分，这部分还在缓存中，那么要让缓存失效 图 5.3: Linux 的 Page Cache 图源. Linux 的 Page Cache 我觉得这篇文章以及这一系列的文章都写得不错，对IO有进一步了解兴趣的话可以去看 接下来，通过几个实验来验证 Linux 的文件预读和缓存机制 首先，我们准备一个 4G 内存的机器，和一个 8G 的文件，并保证这个文件不在系统的 Page Cache 中 # free -wh total used free shared buffers cache available Mem: 3.8Gi 192Mi 3.4Gi 716Ki 16Mi 203Mi 3.6Gi Swap: 0B 0B 0B # vmtouch -v testfile.img # 展示文件有多少在内存缓存中 testfile.img [ ] 0/2048000 Files: 1 Directories: 0 Resident Pages: 0/2048000 0/7G 0% Elapsed: 0.10211 seconds 接下来，我们读取一下这个文件，这是第一次读取后的结果 # vmtouch -v testfile.img testfile.img [oooooooooooooooooooooooooooooooooooOOOOOOOOOOOOOOOOOOOOOOOOO] 911200/2048000 Files: 1 Directories: 0 Resident Pages: 911200/2048000 3G/7G 44.5% Elapsed: 0.31019 seconds # free -wh total used free shared buffers cache available Mem: 3.8Gi 189Mi 31Mi 716Ki 15Mi 3.6Gi 3.6Gi Swap: 0B 0B 0B 可以看到，随着文件的读取，系统只缓存了后半部分的内容，这是由于前半部分在内存中放不下了，被置换出去了。 因此，可以发现一个简单的道理，对于内存中存储不下的巨量文件，如果这个文件不满足局部性原理，缓存几乎是没有作用的。我们可以尝试着多读取几遍这个文件，看看性能有没有改善。 # time cat testfile.img &gt; /dev/null cat testfile.img &gt; /dev/null 0.32s user 36.07s system 20% cpu 3:01.72 total # time cat testfile.img &gt; /dev/null cat testfile.img &gt; /dev/null 0.24s user 34.55s system 19% cpu 3:00.17 total # time cat testfile.img &gt; /dev/null cat testfile.img &gt; /dev/null 0.28s user 32.02s system 19% cpu 2:46.45 total 可以看到，性能几乎没有改善。 这个问题在设计数据库时也是需要关注的，如果要利用操作系统的缓存，那么可能会同时访问的数据要放在相邻的位置上。 接下来，我们实验系统的文件预读功能，我会把 Page Cache 先全部清除，然后从文件中读取 120K 的文件，我们看看系统读取了多少数据到内存中。 # sysctl -w vm.drop_caches=3 vm.drop_caches = 3 # vmtouch -v testfile.img testfile.img [ ] 0/2048000 Files: 1 Directories: 0 Resident Pages: 0/2048000 0/7G 0% Elapsed: 0.11164 seconds # dd if=testfile.img of=/dev/null bs=1K count=120 120+0 records in 120+0 records out 122880 bytes (123 kB, 120 KiB) copied, 0.0074944 s, 16.4 MB/s # vmtouch -v testfile.img testfile.img [o ] 92/2048000 Files: 1 Directories: 0 Resident Pages: 92/2048000 368K/7G 0.00449% Elapsed: 0.13552 seconds 可以看到，虽然我们只读取了 120K 的数据，但系统把文件开头的 368K 都读进了内存中。 5.2.5 O_DIRECT 有没有办法完全阻止操作系统来做这些文件的缓存操作呢？ 如果你做了一些简单的搜索，你会发现网络上大量推崇使用 O_DIRECT 来绕过 Linux 系统的 Page Cache ，这并不一定正确。 O_DIRECT只是程序向系统许下的一个愿望，而非一个命令 在遇到这些需要明确系统行为的问题时，我鼓励读者阅读官方的文档，而不是阅读博客之类的二手知识。 open(2) - Linux manual page 这是官方 manual 中关于 O_DIRECT 的解释 ​ O_DIRECT (since Linux 2.4.10) Try to minimize cache effects of the I/O to and from this file. In general this will degrade performance, but it is useful in special situations, such as when applications do their own caching. File I/O is done directly to/from user-space buffers. The O_DIRECT flag on its own makes an effort to transfer data synchronously, but does not give the guarantees of the O_SYNC flag that data and necessary metadata are transferred. To guarantee synchronous I/O, O_SYNC must be used in addition to O_DIRECT. See NOTES below for further discussion. A semantically similar (but deprecated) interface for block devices is described in raw(8). 可以看到，文档中说对于使用 O_DIRECT 这一 flag 打开的文件，系统只是会尽力保证不使用缓存，不能提供任何保证。同时还特别强调，如果要保证完成写入操作时文件已经写入到磁盘上，应该额外使用 O_SYNC 这一 flag。 那么 O_DIRECT 为什么只能提供尽力的保证呢？因为事实上最终的行为还依赖于 Linux 内核的版本、磁盘挂载时的选项、文件系统提供的支持等。 举例来说，某些文件系统（如 btrfs）在修改文件时并不会在原地进行修改，而是使用 Copy On Write 的方式来优化性能，这些实现细节都会影响最终提供的保证。总结来说，对于不直接使用分区而是使用文件的数据库来说，文件系统是一个极大的变数。例如在www.phoronix.com中，评测了不同文件系统对数据库性能的影响。 5.3 SSD特性与随机读写性能 在之前的一定篇幅中，简单介绍了机械硬盘的基本特性，这篇文章会补充介绍 SSD 的相关特性，另外还包括一个小实验，用于验证硬盘的性能，让读者对硬盘性能有进一步感性的认识。 很多人认为，由于有了 SSD ，数据库的性能相比机械硬盘就相差无几了，甚至认为，对 SSD 可以任意进行读写而不必考虑优化，诚然，SSD 相比机械硬盘的提升是指数级的，但这并不意味着 SSD 本身的特性上没有明显的问题和需要注意的地方。 在开始之前，我还要补充一个关于存储的基本知识。 什么是随机存储器，什么是非随机存储器呢？ 其实，在这块并没有很明确的定义，随着闪存的普及，硬盘也可以在某种程度上认为是一个“随机访问存储器”，但我还是要指出，SSD 所使用的 NAND Flash 和 DRAM 为代表的“随机访问存储器”有着明显的区别。 我在这里明确定义：如果一个存储器，可以按照处理器的“字” (WORD) 为单位进行随机读写，那么它就是随机存储器，反之，它就不是。 图 5.4: 不同存储器最小读取大小的对比 根据上述定义，抛开 Optane 等新兴的非易失性内存不谈，我们的硬盘都是不支持随机访问的，不论是机械硬盘还是 SSD ，都不支持随机访问。用之前的文章中提到的概念来说，块设备都是不支持随机访问的。这是由它们的硬件特性决定的。 关于机械硬盘为什么随机性能很差，之前已经介绍过，这里补充介绍 SSD 的特性： SSD 的底层使用的存储介质是 NAND Flash，NAND Flash 的最小读取单位是一个 Page ，而最小重编程单位更是达到了一个 Block ，这意味着，对 SSD 来说，每次最小读取一个 Page (越是新的 NAND Flash 页大小越大，10 年前 (2013) 的主流 Page Size 是 8K) ，而每次更新数据时的最小写入单位更是达到了一个 Block ，通常是 64~128 个 Page （随着闪存容量变大，这个值还会变大）。 图 5.5: 2015年量产的TH58TEG8DDKTA20闪存的页大小已经高达16KB 图 5.6: Nand Flash结构示意图，图源AnandTech 而，如果我们要随机读取大量的小文件，造成的读写放大都是巨大的。如果 SSD 每次最小读取 64KB ，而要读取的数据大小是 4K，那么就存在 16 倍的读取放大。 这里，我们可以简单写一个程序来测试硬盘的随机 4K 读取性能，可以看到，对于 OS 无法进行预读缓存的随机 4K 读取，即使是在 SSD 上也存在巨大的性能损耗。 import os import random class IOBenchmark: def __init__(self): self.RANDOM_FILE_NAME = &quot;random_file.pytest&quot; def createRandomFile(self, sizeInMegaByte=1024): with open(self.RANDOM_FILE_NAME, &#39;wb&#39;) as fout: fout.write( os.urandom(sizeInMegaByte * 1024 * 1024)) fout.flush() os.fsync(fout) def random4KRead(self, ioOperations = 30000): import time with open(self.RANDOM_FILE_NAME, &#39;rb&#39;) as fin: t0 = time.time() for i in range(ioOperations): fin.seek(random.randint(0, os.stat(self.RANDOM_FILE_NAME).st_size)) fin.read(4096) print(&quot;Performed {0} iops 4k random read in {1} seconds&quot;.format(ioOperations, time.time()-t0)) if __name__ == &#39;__main__&#39;: ioBench = IOBenchmark() # ioBench.createRandomFile() ioBench.random4KRead() 仅仅是进行 30000 次随机的 io 读写，性能如何呢？这里我在 SATA 的固态硬盘上做了个简单测试 图 5.7: 30000次随机4k读取测试 可以看到，仅仅是 30000 次的随机读，就要花费 5.6秒 的时间。折算下来的读取速度大约是 20MB/S ，这符合 SATA SSD 的典型性能表现 除了介质本身存在如此大的读取放大损失外，设备本身的响应时间也十分慢。永远记住，假设 CPU 从 L1D 取数据的速度是 1 秒，那么 CPU 从 SSD 取数据的时间大约是 1 天。 5.4 文件系统 在之前的文章中，简单介绍了硬盘与操作系统交互的方式。读者现在应该已经认识到硬盘可以被抽象为一个“块设备”，并且对硬盘的硬件特性有了一些了解。但仅仅这样距离硬盘可以被用在实际使用中还有一些距离。举例来说，有下面这些关键的问题没有解决。 很显然，作为用户，我们不可能直接去操纵硬盘并记忆数据的地址。那么： 用户如何决定要将数据存储在哪里？ 用户如何快速索引出之前存进硬盘里的数据？ 为了解决这些问题，需要文件系统的支持。 文件系统决定了用户的数据在硬盘上的组织方式，不同的操作系统有不同的文件系统，比如，Windows 常用的文件系统是 NTFS ，Linux 系统比较常用的文件系统是 EXT4 。每个文件系统的特性都有不同，不同的文件系统适应不同的使用场景。下面我会简单介绍一下文件系统的基本常识。 5.4.1 FAT32简介 上文简单介绍了文件系统的概念，但可能没有办法帮助读者建立起具象的印象，因此，在这一小节我会选取一个简单的文件系统作为例子来讨论它是如何工作的。 这里，我直接引用 FAT32 文件系统的结构。FAT32 是微软在上世纪 90 年代推出的文件系统，在早期曾经作为 Windows XP 等系统的系统分区默认文件系统，但现在已经几乎完全淘汰，只有少数的可移动存储设备在使用 FAT32 文件系统，FAT32 是 FAT (File Allocation Table, 文件分配表) 文件系统的 32 位版本，是这一系列文件系统的最后版本，从这个文件系统的名字也可以看出来，这种文件系统相对是比较原始的，很适合用来举例子和学习。 图 5.8: FAT32的四个主要部分和其作用 5.4.2 簇 在 FAT32 文件系统中，管理存储数据的最小单元是“簇”，一个簇的大小是扇区的 2^n 倍，举例来说，一个簇可以是 2个、4个、8个…64个 扇区。 FAT32 将最小管理单位定位可变的簇，主要原因是扇区这一硬盘的原始单位实在是太小，仅仅只有 512 个字节，如果使用扇区来作为文件系统中文件的地址直接使用，不仅会更多地占用文件分配表（文件分配表直接记录了文件的簇地址），还容易出现更多的文件碎片（即，一个文件被打散在多个不连续的簇上，影响读写性能）。根据簇的定义，一旦给定了某个文件系统的簇的尺寸，就可以根据簇的编号直接定位到簇所在的扇区。 5.4.3 FAT FAT32 管理文件位置的工具被称为文件分配表（FAT），文件分配表是一段固定大小的空间，和数据区的簇的数量一一对应，有多少个簇，文件分配表中就有多少条记录。而每条记录在文件分配表中占 32 个比特，这也是 FAT32 这一名字的由来。 文件分配表的作用是用来在提示对应的簇上有没有文件，以及对应的簇存储的文件是在簇内就结束了，还是需要再读取下一个簇来读取下一部分。因此，文件分配表可能看起来像是这样： 图 5.9: FAT的簇链 5.4.4 目录管理 目录（文件夹）可能在一些读者眼中是一种相对特殊的概念，读者可能认为目录没有办法作为普通文件来管理。事实上，在 FAT32 中，目录和普通文件的管理方式完全一致，这也大大降低了文件系统的复杂度。 在 FAT32 文件系统中，目录也是一种特殊的文件，这种文件上记录着文件夹下对应有哪些文件和它们对应的簇，和其他文件一样，如果一个簇存不下所有的文件信息，那么就可以在 FAT 表新增一条记录接着记录。 5.4.5 FAT32的灾难恢复 FAT32 文件系统包括四个部分：DBR 、FAT1 、FAT2 和 数据区。其中，DBR 是一段固定大小的区域，这块区域主要记录用来加载文件系统所必需的信息，例如文件系统的类型、簇的大小、FAT 的起始位置等，有了这些信息，文件系统驱动才能准确地识别出文件系统。关于 DBR 和 FAT 的作用，之前已经说明，现在主要说明 FAT2 的作用，以及 FAT32 文件系统如何在崩溃中恢复： FAT1 和 FAT2 是两份完全一样的文件分配表，之所以保留 2 份，是为了当出现 FAT1 损坏的时候可以用 FAT2 进行替换。FAT2 是 FAT32 恢复机制的一部分。 读者可能想到，FAT2 中的数据不一定是最新的，这也就意味着尽管文件系统可能会恢复，但是用户已经写入的文件有可能会丢失，已经删除的文件也可能又出现。为了避免这一问题，有对应的被称为 chkdsk 的工具。这一工具会对 FAT32 全盘进行扫描，而不是依赖 FAT 来进行文件的发现。当它扫描到实际存在但在 FAT 中不存在的文件时，就会将它们添加到 FAT 中，以前的操作系统里在分区的根目录通常会有 LOSTFOUND.000 的目录，这一目录的作用就是存储 chkdsk 扫描全盘发现的文件。这就是 FAT32 的崩溃恢复过程。 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
