[["index.html", "ElementDB the Book 84322d7 第 1 章 序言", " ElementDB the Book 84322d7 ar8327 2024-02-13 第 1 章 序言 构建一个数据库是一项庞大、复杂的工作，我也并不是专业有过数据库构建经验的人，所以，我想在文章的开篇就说明白，接下来这些文章的目的、受众以及我将如何展开。 首先，这并不是一份专业性的数据库材料。我会尽可能将我的想法描述清楚，但我描述的内容中可能有不专业、不准确的地方，欢迎指正。这份资料本身的受众是对这些话题有兴趣但没有专业背景的业余爱好者。 再次，这份资料的目的是记录我个人学习数据库相关知识时学习到的知识，以及我自己在实现数据库时自己的思考。我通过将这些知识整理成系统性资料的方式来提高我自身对知识的理解，也能帮助需要的朋友更好地学习。 最后，来介绍一下这份资料的组织形式。 首先聊一聊接下来这些资料的逻辑： 我会先讨论一些关于数据库系统的通用知识，例如什么是事务、什么是 SQL 、什么样的系统是一个数据库系统。在这一过程中，我会尽可能展示这些问题的复杂性，通过展示问题的复杂性，可以让读者对之后解决问题的过程产生兴趣，同时，也有利于激发新的思考。 随后，我会介绍一个数据库系统大致应该有哪些组成部分，各个部分的作用，以及建立一个数据库的模型。在之后，我会详细展开每个部分的理论基础和系统设计，辅以部分实践和杂谈。 我接下来写的资料会大概属于四个分类： 理论，这部分文章会相对严肃一些，阐述一些关于数据库系统的基础理论。例如，要阐述 B+ 树的设计、并发控制机制等，这部分内容会相对干一点，但这是后续所有工作的理论基础，保证我们系统的正确性。 系统设计，这部分在理论的基础上，会讨论在工程上实际实现系统的取舍。同一种理论上的系统模型，有多种实现方式，而不同的实现方式，会产生系统实际性能表现等方面的不同，这就涉及到取舍，是需要重点讨论的。 实践，这部分并不全部是要介绍我写的代码，甚至介绍代码的工作可能只占一小部分，也想设计一些小实验来测试、证实我在文章中所说的观点。我推荐读者也做一下这些实践，可能是自己写一份测试性能的代码，也可能是自己写一个 mmap 的 demo ，通过做这些事情能提高读者的编程能力，这是最基础的能力。 杂谈，杂谈这一块我会发散地讨论一些和数据库系统本身无关，但可能有借鉴价值，或者属于基本素质的内容。 ar8327 2023 年 10 月 "],["intro.html", "第 2 章 问题引入 2.1 构建一个员工信息管理系统 2.2 员工信息管理系统的问题", " 第 2 章 问题引入 2.1 构建一个员工信息管理系统 在动手设计实现数据库之前，不妨先花一点时间头脑风暴一下数据库是什么。 其实，大部分的程序员在编写应用程序的时候，都不会意识到数据库承担了多少工作，这恰恰说明了数据库概念的成功，将数据存储、并发控制、一致性保证等功能从应用中切分出来，并且运用“事务”等概念来实现存储层功能的接口化，是一项了不起的工作。 为了更好地帮助读者认识到数据库的概念，我先从尝试着在不使用数据库的情况下实现一个员工信息管理系统开始，请读者和我一起思考，我们一起分析可能遇到的问题，并且思考数据库是如何解决它们的。 存储的逻辑结构 假设现在我们需要存储一些雇员的信息，这些信息这么定义：员工信息:(姓名, 电话, 年龄) 一条员工信息包括员工的姓名、 员工的电话和员工的年龄。 系统支持的功能 我们的信息管理系统要支持以下功能： 我们要可以插入新的员工信息到系统中，方便为新员工注册信息 我们要可以使用员工姓名查询员工信息，这样公司内的人能够通过姓名查询到他人的信息 为了存储信息，我们可以使用操作系统和文件系统提供的基本文件操作功能，可以在文件系统中创建空白文件，可以向文件中添加信息，也可以从任意位置读取文件。 系统的简易实现 有了上面这些条件，我可以给出一个比较简单的“员工信息管理系统”实现： 在这个实现中，我给每一条记录开启一个新的行，每一行中存储对应的员工信息， 每个员工信息的属性称为一列，每一行含有多个列，分别为员工信息的不同属性 在插入用户信息时，我保证写入的数据都符合这个格式 在查找用户信息时，我根据预先约定好的数据格式去解析数据文件，获取记录的雇员姓名，并返回所有符合要求的记录。 在具体实现上，为了遵循这一协议约定，我使用空文件来存储信息，在行与行之间使用 \\n 分割，同一行的列之间使用 &lt;SEP&gt; 分隔。 下面是一个简单的实现版本： import io class EmployeeManager: def __init__(self): self.DBFILE = &quot;employees.txt&quot; self.db = open(self.DBFILE, &quot;a+&quot;, encoding=&#39;utf-8&#39;) self.SEP = &quot;&lt;SEP&gt;&quot; def write(self, name, phone, age) self.db.seek(0, io.SEEK_END) self.db.write(&quot;{0}{1}{2}{3}{4}{5}\\n&quot;.format(name, self.SEP, phone, self.SEP, age, self.SEP)) self.db.flush() def findByName(self, name): self.db.seek(0) for line in self.db.readlines(): line = line.strip() line = line.split(self.SEP) if line[0] == name: self.db.seek(0) return line self.db.seek(0) return None if __name__ == &#39;__main__&#39;: emp = EmployeeManager() emp.write(&quot;Tom&quot;, &quot;+8613042552664&quot;, 32) emp.write(&quot;Marry&quot;, &quot;+8613142357624&quot;, 29) # Try to find Tom tom = emp.findByName(&quot;Tom&quot;) if tom: print(&quot;Tom exists&quot;) jack = emp.findByName(&quot;Jack&quot;) if jack: print(&quot;Jack exists&quot;) emp.write(&quot;Jack&quot;, &quot;+8613051531&quot;, 34) 最后，我们用一幅图来总结说明刚才我们所做的设计。用两个视图来概括，在文件的物理视图中，我们的文件如右图所示，而在程序和协议中，我们的数据表如左图所示。 图 2.1: 雇员文件逻辑视图 图 2.2: 雇员文件物理视图 2.2 员工信息管理系统的问题 在前文，我们一起实现了一个简单的员工信息管理系统。尽管这个数据库能够满足基本的功能需求，但它不可否认地存在一些缺陷。 在本文中，我会罗列这个信息管理系统可能出现的一些问题，并通过将这些问题分类，来识别数据库系统所做的工作、提供的保证： 与物理存储结构绑定的查询和写入逻辑 没有一种通用的查询语言，每个查找需求都需要编写单独的查找方法 findByName 方法、write 方法都直接与底层的数据存储方式耦合，查找数据的逻辑竟然需要精确到读取第几个字段，这是一种命令式 (imperative) 的做法，与目前的 SQL 语言的声明式查询是相对的，命令式的查询语言将底层实现暴露给最终用户，使得查询语言与底层实现耦合，这在日后是维护的噩梦 缺乏并发控制，读写操作互相排斥 数据库在写入的时候缺乏并发控制，可能出现两个进程同时写入一个文件的情况，造成文件损坏 findByName 方法同样不是并发安全的，可能在一个进程读取文件时另一个进程将文件 rewind 由于直接依赖底层文件的指针位置，读写无法同时进行 数据持久化与数据完整性检查 若在执行 write 方法的时候，flush 的时候系统断电，则会导致数据文件损坏，缺乏错误检查机制 若在执行 write 时，系统完成了 write 操作还没有flush时系统断电，会造成数据完全丢失 缺乏唯一索引约束能力 write 方法缺乏对记录的唯一性校验，如果用户犯错，系统就会写入多条相同的记录 性能问题 findByName 方法异常低效，每次都需要遍历整个文件查找记录，也不具备自己的缓存 缺乏字段类型、数据格式和存储低效 数据文件对数据格式缺乏校验和表示，写入的所有东西都会变成 string 数据文件用的是文本格式，空间效率十分低下 缺乏表结构灵活性 如果要新增一个员工性别字段怎么办？之前的数据如何迁移？ 尽管提出了许多问题，且似乎每一个这些问题都有简单的解决方式，但若要考虑一个能够解决所有问题的方案，似乎问题就会变得复杂。 举例来说，如果是为了解决缺乏唯一索引的问题，我们可以实现一个方法，在写入数据前先遍历整个文件，看看是不是有重复的数据，如果有的话就拒绝写入。但这样的实现也会让写入的性能进一步下降。 那么，有没有什么办法可以比较好地解决上面的全部问题呢？其实是有的。为了解决上面的问题，需要引入现代数据库系统的多个概念。从下一篇文章开始，我就会开始介绍数据库系统中的关键概念，并看看我们如何利用这些工具来解决上面的问题。 "],["intro-to-dbms.html", "第 3 章 DBMS简介 3.1 数据库系统发展简史 3.2 数据库系统的模块", " 第 3 章 DBMS简介 3.1 数据库系统发展简史 在 1960 年代，计算机刚被发明不久，当时计算机远没有普及，软件生态相较今天也十分简单。但在当时，就已经有大型公司尝试着使用计算机来管理数据了。 使用计算机来管理数据有很多好处，相较于传统的纸质数据管理方式，计算机一次性能够记录更多的数据，在数据的检索和管理上也更为容易，存在数据更不容易丢失等优势。 1960 年代主要的数据库系统是以 IDS 为代表的层级数据库。这么说可能会让读者没有概念，因此，为了描述数据库系统，我首先展开一下数据库系统的几个基本概念。 3.1.1 数据模型 所有的数据存储都依赖一个事先定义好的数据模型。以大家熟悉的 MySQL 举例，MySQL 是一种关系型数据库管理系统 (Relational DBMS) 。 MySQL 的数据模型是基于关系代数建立的，在 MySQL 中，所有的数据都从属于一个“表”，这个“表”可以与其他“表”进行关系代数运算。这就是一种非常典型的数据模型。 3.1.1.1 层级数据库 最早期的数据库大部分都是层级数据库 (Hierarchical Database)，在层级数据库中，所有的数据都是按照层级组织的。通常来说，这种类型的数据库中都有一个根结点，当用户需要寻找什么数据的时候，需要手动操作数据库，从根结点出发，定位到自己想要的数据。 举例来说，如果要存储书和作者的关系，可能看起来是下面这样： RECORD Author AuthorID: INTEGER Name: STRING Birthdate: DATE Books: SET OF Book RECORD Book BookID: INTEGER Title: STRING PublicationDate: DATE Author: REFERENCE TO Author // 定义作者 AUTHOR_1 = Author(AuthorID=1, Name=&quot;J.K. Rowling&quot;, Birthdate=&quot;31/07/1965&quot;) AUTHOR_2 = Author(AuthorID=2, Name=&quot;George Orwell&quot;, Birthdate=&quot;25/06/1903&quot;) // 定义书 BOOK_1 = Book(BookID=1, Title=&quot;Harry Potter and the Sorcerer&#39;s Stone&quot;, PublicationDate=&quot;26/06/1997&quot;, Author=AUTHOR_1) BOOK_2 = Book(BookID=2, Title=&quot;1984&quot;, PublicationDate=&quot;08/06/1949&quot;, Author=AUTHOR_2) // 通过这种方式将作者和书链接起来 AUTHOR_1.Books = [BOOK_1] AUTHOR_2.Books = [BOOK_2] // 查询的例子 // 找到所有AUTHOR_1写的书 for book in AUTHOR_1.Books: print(book.Title) // 获取BOOK_2的作者名 print(BOOK_2.Author.Name) 可以看到，在这种数据模型下，用户需要手动跟踪数据中存储的指针，直到找到自己的数据位置 1960 年代时，主要的数据库就是这种形式。这种形式的数据库中查询数据很复杂，和关系型数据库相比，不仅不能一次性使用外键连接多个表，而且查询数据的方式主要依赖代码实现，很难让用户单独使用命令查询。 在 1970 年代，随着关系代数的论文被发表，关系型数据库的概念开始兴起。我们今天所熟悉的 SQL 也被发明了。 IBM 的 System R 是第一个实现了关系代数模型的数据库产品。不过，由于当时的计算机尚未普及，对数据库系统系统的需求基本还停留在大型公司，其他大部分公司没有对数据库产品的需求。但 1970 年代的意义是重大的，因为关系型数据库这一时至今日仍然流行的数据模型就是在那时被确立的。 当然，尽管有了关系型数据库的雏形，当时的数据库系统还有很多基础研究没有完成。举例来说，对于数据库系统应该如何处理并发请求，如何管理锁来避免用户数据出现问题，直到 1990 年代才有系统性的论文出现。 随着计算机和互联网的普及，数据库系统不再是单纯的为大公司服务的昂贵系统，举例来说，1995 年微软发布了 Microsoft SQL Server ，这是一款能够运行在普通个人计算机上的数据库管理系统，而随着互联网的发展，越来越多的网站被建立起来，对数据库系统的需求激增，因此，以 MySQL 、MsSQL 、Postgres 等为代表的可以运行在普通个人计算机上的数据库系统从 1990 年代开始流行。 3.1.1.2 关系型数据库 在 1990 年代流行的数据库就是关系型数据库了，这个时候的数据库已经和今天大家熟悉的数据库很相似，我就不多做介绍。需要指出的是，今天大家很熟悉的 MySQL 在当时功能十分简单，是一个类似 KV数据库 的数据库。在 Innobase 将 innodb 捐献给 MySQL 之后， MySQL 才拥有了今天这些大家熟悉的功能。在 InnoDB 之前， MySQL 的默认存储引擎 MyISAM 不支持外键这种基本的关系型数据库功能，也不支持行锁这种基础的并发控制，是一个功能相对较弱的数据库。 3.1.1.3 NoSQL与NewSQL 在关系型数据库流行之后，随着互联网的进一步发展，对数据库系统也提出了新的要求，例如，非结构化数据存储，或者是大量数据的分区存储、分析能力，这些不是传统的关系型数据库能够支持的。因此，随后的数据库发展朝着两个方向进行： 第一个方向是发明各种新型的数据模型，例如文档数据库、图数据库，这些基于特定数据模型的数据库在特定的应用场景下相较关系型数据库有更大的优势。 第二个方向是进行数据库架构的演变，以支持不同的场景和灵活的性能要求，例如 Google 的 Spanner 就是典型的一种分布式、超大型数据库。 3.2 数据库系统的模块 不论数据库系统有哪些功能、实现哪种数据模型，在一些地方始终是相通的。本文介绍数据库系统通常的架构是什么样的。 我们来考虑一个基本的数据库系统，它至少包含以下两个部分： 用来处理用户请求的部分 用来管理数据存储的部分 通常，第一个部分被称为数据库系统的前端，而第二个部分被称为数据库系统的后端。 接下来， 我们分别考察这两个部分。 3.2.1 数据库的前端 3.2.1.1 查询解析器 这部分需要解析用户输入的命令，判断用户命令的合法性，举例来说： FELECT * FROM table1 LIMIT 0,10 这句 SQL 命令就不是一句合法的 SQL 命令，因为实际上不存在 FELECT 这一关键词 事实上，市面上的大部分数据库前端都会将用户输入的命令解析成抽象语法树 (AST) ，供后端处理，举例来说，下面是一颗解析 SQL 的 AST ： &lt;select-statement&gt; ├── &lt;column-list&gt; │ └── &lt;column-name&gt; │ └── name ├── &lt;table-name&gt; │ └── students └── &lt;condition&gt; ├── &lt;expression&gt; │ ├── &lt;MARK&gt; │ │ └── age │ ├── &lt;OP&gt; │ │ └── &gt; │ └── &lt;CONST&gt; │ └── &#39;18&#39; ├── &lt;logical-op&gt; │ └── AND └── &lt;expression&gt; ├── &lt;MARK&gt; │ └── gender ├── &lt;OP&gt; │ └── = └── &lt;CONST&gt; └── &#39;M&#39; 3.2.1.2 查询优化器 这部分做的事情主要是对用户输入的查询命令进行一个优化，需要注意的是，在数据库的后端实际上也存在执行计划的优化操作，这部分仅仅讨论的是对 AST 的优化操作。 例如，考虑这么一句 SQL ： SELECT * FROM table1 WHERE col1 &gt;= 10 AND col1 &lt;= 10 这句 SQL 实际上可以被等价优化成： SELECT * FROM table1 WHERE col1 = 10 这种基于 AST 的纯粹优化有很多好处，举例来说，如果不进行这样的优化，那么数据库后端在执行这个查询的时候大概率在执行的时候是这么执行的： 先找出所有满足 col1 &gt;= 10 或者 col1 &lt;= 10 的记录，然后检查是否满足其他条件。 这种查询显然是十分低效的，远不如根据 AST 优化后的结果。 3.2.2 数据库的后端 3.2.2.1 系统字典 数据库系统要对外维持自己的数据模型，就需要维护一些特定的信息。举例来说，如果是一个关系型的数据库，就需要维护自己目前库中有哪些表，表中有什么字段，哪些字段上存在索引这些信息。这一类的信息我们统称为数据库的多数据字典信息，属于是数据库系统自行维护的数据库元信息。数据库很大程度上需要依靠这些元信息来判断查询是否合法，以及如何执行查询。举例来说：当用户需要根据某一条件进行某一查询时，数据库需要根据元信息判断条件字段上是否存在索引，以此来决策具体的执行计划： SELECT * FROM table1 WHERE col1 = 10 对于这句查询语句，数据库系统就需要根据元信息来查询这么几个点： table1 是否存在 table1中有哪些字段 table1的数据存储在哪里 col1上是否有索引 3.2.2.2 查询计划器 查询计划器是所有数据库系统中最为复杂的部分，用于将逻辑上用户需要进行的查询计划转化为物理的执行计划，要明确到需要根据什么查数据，查什么数据，查到了数据之后进行怎么样的处理，具体的算子下沉还是上升等等问题，生成和优化物理执行计划本身是一个NP问题，这也是各个高性能数据库的技术核心。 在用户输入的命令被解析成 AST 并且通过数据字典的基本校验后，就进入到了查询计划器当中。 举例来说，考虑这么一条 SQL ： SELECT * FROM table1 WHERE col1 &gt;= 10 AND col2 &lt;= 10 这里其实有三条明显的执行路径： 直接扫描全部数据，然后根据条件筛选 根据索引拉出所有 col1 &gt;= 10 的数据，然后筛选满足 col2 &lt;= 10 的 根据索引拉出所有 col2&lt;=10 的数据，然后筛选满足 col1&gt;=10 的 哪个执行方案才是更优的呢？这就需要一些额外的信息辅助判断了： 例如，如果我们知道 col1&gt;=10 的数据只有大概 10 条，而 col2&lt;=10 的数据有 100000 条，那么显然第二个执行计划是更好的 反之，如果我们知道 col2&lt;=10 的数据明显少于 col1&gt;=10 的，那么显然第三个执行计划成本就更低 当然，如果说 col1 、col2 上不存在索引，或者说表的数据量很小，由于 id 在我们的数据库里是聚簇索引，不需要回盘查第二次，那可能直接拉所有的数据是更好的 3.2.2.3 事务管理器、锁管理器、并发控制器 这一部分，主要是大部分数据库都保有的、为了维持系统正确性、提供并发安全等而提供的机制，如果你的数据库要支持一些并发和隔离特性，那么需要一些额外的组件来支持数据库的正常工作。 这部分是一个比较复杂的问题，举例来说，对于以下2个同时执行的事务： SELECT * FROM table1 WHERE col1 = 10 FOR UPDATE SELECT * FROM table1 WHERE col2 = 10 FOR UPDATE SELECT * FROM table1 WHERE col1 = 10 FOR UPDATE SELECT * FROM table1 WHERE col2 = 10 FOR UPDATE 这 2 个事务就会出现互相等待对方释放锁的情况，进而造成死锁，这是不可接受的情况，需要有一个事务主动回滚，才能解决这一问题。 同样地，一些复杂的并发场景需要数据库系统主动识别才能避免问题发生，例如： SELECT id FROM table1 WHERE col1 = 10; -- 事务1，结果id=10 UPDATE table1 SET col1 = col1 + 10 WHERE col1 = 10; -- 事务2，提交 UPDATE table1 SET col1 = (10) + 10 WHERE id = 10; -- 事务1，提交 上述的问题就是一个明显的并发问题，事务1读取并使用过期的值来对数据进行更新。 由于这部分的内容相对比较复杂，要系统性的描述需要比较大的篇幅，在之后的内容中会进一步进行讨论。目前仅仅讨论到存在的问题和需要引入解决这些问题的组件。 3.2.2.4 缓存池 当执行计划被确定之后，就会对硬盘进行大量的 io操作 ，理论上，这些 io操作 很可能是随机的，至少也是随机混合的，这一类的读写模式对硬盘不友好，而实际上，即使这种模式对硬盘是友好的，硬盘的数据读取时间对于 CPU 来说也是十分漫长的。 图 3.1: 各种介质的延迟 图源 https://blog.bytebytego.com/p/ep22-latency-numbers-you-should-know 因此，所有的io操作最好是在内存中进行，由缓存池负责对硬盘的实际io读写调度 3.2.2.5 索引 数据库系统大量需要索引来辅助查找和存储数据，如果没有索引的帮助，数据库系统每次查找数据时只能对所有数据进行遍历，这是不可接受的。而目前常见的两种用于在硬盘数据上建立索引算法是 B树 (包括 B+树 等各种衍生)和 SSTable 。这些算法不仅是要尽可能高校地满足各类查询和插入需求，更重要的是要能够契合硬盘的硬件特性，尽可能减少读取硬盘的次数，一次尽可能多的读取数据而不是多次读取少量数据。 3.2.2.6 物理文件管理器 最后我们要提到的是物理文件管理模块，这里的模块负责的是硬盘空间的管理，这也是一个相对来说有一些复杂的问题。 举例来说，考虑我们需要向数据库存储一份数据，这份数据长 1000 个字节，那么存储引擎就需要考虑几个问题： 在哪里存这份数据？空间如何分配？ 如果有数据最近被删除了，怎么回收之前的数据供使用？ 怎么样存储数据才能尽可能提高查询效率？ 这些问题一定程度上也决定了数据库的性能表现 以上是对数据库系统各个常见模块的一些介绍，这些内容对理解接下来的行文思路会有很大帮助。 "],["query-language.html", "第 4 章 查询语言 4.1 数据模型与查询语言 4.2 定义自己的简单类SQL语言 4.3 实现一个简单SQL解析器", " 第 4 章 查询语言 4.1 数据模型与查询语言 要设计一个数据库系统，第一步就是设计其对外的接口——外界要如何操作数据库中的数据，如何查找数据？ 要解决这个问题，首先要定义一种数据模型。 数据模型主要包括两个部分：其一，其定义了数据在数据库中的逻辑表示，其二，其定义了外界操作数据的法则。 数据模型的意义在于，通过定义一套数据模型，我们可以用指定的语言描述我们想要的数据，剩下的工作就全部可以交给数据库系统进行，而不用我们关心。 图 4.1: 查询语言 历史上，有非常多的数据模型，在此，我简单介绍几种。 4.1.1 层次(Hierarchical model)模型 在层次模型里，数据是通过类似树的形式组织的。 IBM 的 IMS 最先使用的是层级模型，IBM 为之开发了一种独特的数据查询语言，名为 DL/I (Data Language/One)。 下面是几个 DL/I 的例子： GET CUSTOMERS BY NAME = &#39;SMITH&#39; GIVE ADDRESS PHONE 在这里，GET 是 DL/I 的关键词，它表示要从 CUSTOMERS 这一数据集中获取数据。 BY 在这里也是一个关键词，表示要使用的筛选条件，最后，GIVE 关键词表示返回的数据中仅需要 ADDRESS 和 PHONE 这两个字段。 上面这个例子还不能很好地说明数据的层次结构，下面这个例子能够更好地说明这一点： 考虑你需要获取所有状态为 PENDING 的订单号和它对应的顾客姓名，你可以使用下面的语句： GET ORDERS BY STATUS = &#39;PENDING&#39; GIVE ORDER-ID CUSTOMER-NAME 通过上面两个例子，你应该可以发现，在 DL/I 中，数据是按照一棵树的形式展开的，ORDERS 表的结构大致如下： ORDERS ORDER-ID (integer) CUSTOMER-NAME (string) STATUS (string) 而 CUSTOMER 则是上文中我们提到的另一个表： CUSTOMERS NAME (string) ADDRESS (string) PHONE (string) 尽管在查询时通过这种方式来处理一对多关系非常便利，但由于其表示多对多关系时存在困难，且维护记录与记录的关系十分麻烦（记录与记录之间通过类似指针的方式关联，因此在更新时需要考虑非常多的内容），这种数据模型在70年代后逐渐被关系模型和 SQL 取代。 4.1.2 关系模型 关系模型是非常重要的模型，时至今日，关系模型及其衍生物 SQL 依然非常流行。 关系模型最初是在 A relational model of data for large shared data banks 这篇论文中由 IBM研究院 在 70 年代提出的，一个数据模型具有如此长久的生命力是非常不可思议的，恰恰说明了关系模型真的解决了之前的诸多问题。 在这篇文章中，作者首先指出了当时存在的层次模型与网络模型的诸多缺点，并提出了关系模型希望取而代之。有兴趣的读者可以进行阅读。上述模型的最重要缺陷之一是由于其对用户暴露了过多数据存储的细节(指针)，进而引入了极大的编程复杂性，因此，关系模型在设计之初的核心思想就是这是一个声明式的模型，不会把关于数据存储的详细信息暴露给用户。 关系模型中，定义了 关系(relations) 和对 关系 的一系列 操作(operations) ，这些简单的操作可以叠加，从而形成复杂的关系表达能力。 3 个基本的关系操作是： 选择操作，可以选择关系中符合对应条件的记录。例如，以下表达式可以选择 Employees 中所有 Salary 大于 50000 的记录。 σ Salary &gt; 50000 (Employees) 投影操作: 投影操作可以从关系集合中选择一部分列。 例如，下面的表达式可以表示从 Employees 数据集中选择记录的 Name 和 Salary 字段。 π Name, Salary (Employees) 连接: 连接操作可以将 2 个关系集合并成一个，通过指定连接字段，可以将拥有相同连接字段值的关系联合起来。例如，下面的表达式可以将 Employees 和 Departments 这 2 个关系通过 DepartmentID 连接起来。 Employees ⨝ DepartmentID = DepartmentID (Departments) 4.1.2.1 SQL SQL 是随着关系模型被提出的，SQL是自然语言化的关系代数表达式。例如，上面的 3 个关系代数表达式对应的 SQL 语句分别是: SELECT * FROM Employees WHERE Salary &gt; 50000; SELECT Name, Salary FROM Employees; SELECT * FROM Employees INNER JOIN Departments ON Employees.DepartmentID = Departments.DepartmentID; 4.1.3 文档模型 最后，在结束之前，再介绍一种随着 noSQL (Not Only SQL)发展普遍被使用的模型——文档模型。 在一个文档模型的数据库中，你可以认为是一个 数据库(bucket) 中保存了 n 个 JSON ，一个数据库是一个 JSON 的 桶(bucket) ，每个 JSON 就是一条记录。这些 JSON 之间不需要有相同的结构，对 JSON 的大小等都没有限制。 与文档模型相比，关系模型要求一切都被定义好，所有的关系都必须预先定义好自己的 schema(列和列的类型) ，如果没有预先定义，那么这个列就无法被搜索和单独访问。然而，随着计算机软件的发展，出现了一些并不适合预先定义好 schema 的数据，另外，文档模型由于是一个 非归一化(denormalized) 的模型，记录与记录之间不会互相依赖，只需要保证单个文档的准确性，也不需要支持传统关系型数据库那样多个表之间的事务保证，在分布式部署等方面具有原生的优势，通常更益于并行计算，能够获得更大的性能收益。 4.1.3.1 层次模型与文档模型的比较 读者可能会觉得文档模型与层次模型有不少相似之处，尤其是他们可以不加限制地嵌套记录这一点。 确实，层次模型看起来与文档模型有非常多的相似之处，但其中最重要的区别在于，层次模型依然存在记录与记录的关联关系——层次模型不保存非归一化的记录，而是保存指针。这种设计导致了层次模型的失败——维护这些关系过于复杂，经常把系统搞得一团乱麻。相比之下，文档模型舍弃了指针设计，不允许文档之间互相关联，这种功能上的牺牲极大降低了数据模型的复杂性。因此，文档模型不会走层次模型的老路。 4.2 定义自己的简单类SQL语言 SQL，即 Structured Query Language ，具有比较强的表达能力，最早在1979年由 Oracle 推向商用数据库市场。 随着关系型数据库的流行， SQL 的影响力日渐庞大，几乎所有的关系型数据库，甚至部分 KV数据库 、 列数据库 也支持 SQL 或 SQL方言 作为数据查询语言和操作语言。 接下来，为了实现我们自己的数据库，我们也需要为我们的数据库选择一种用于操作数据和查询数据的语言。这里，我选择了一种简化的 SQL 语言。这篇文章主要介绍如何定义这种语言。 4.2.1 一点点的编译原理小知识 首先，不妨思考这个问题：如何定义一句 SQL 语句是否合理？如何设计我们自己的 SQL 语法？ 一个答案是使用 BNF范式（巴科斯范式）。 在解析一句 SQL 语句是否合法时，主要包括以下三个步骤。 第一步，词法分析，这一步中，我们会把用户输入的 SQL 语句分为一个个的 token ，每个 token 都是 BNF 中定义的关键词。 第二步，语法分析，在这一步，我们分析 token 的排列规则是否符合预先设定的规则，也就是是否符合我们定义的 BNF范式 的要求。经过语法分析后，我们能得到一些结构化的数据，这些结构对应的就是 SQL 语句的解析结果。比较典型的结构体是 Parse Tree 或者 AST (抽象语法树)。 第三步，语义分析，这一步中我们要分析已经确定符合 BNF范式 的语句是否存在语义上的缺陷，例如，是否在字符串类型的字段中插入了数字，等等。 下面，我会给一些简单的例子来介绍上面的步骤，并最终给出我们的 SQL 语句 BNF 。 4.2.2 词法分析 例如，我们有这样一条 SQL 语句: SELECT name FROM students WHERE age &gt; '18'; 在 词法分析 阶段，我们将该语句分解为以下 token : SELECT , name , FROM , students , WHERE , age , &gt; ,'18' , ; 相信你也明白所谓的 词法分析 的作用了，在这一步中，我们定义一系列规则，来明确在我们定义的语言中什么样的字符可以连接在一起构成一个 token ，什么样的字符自己就是一个 token ，而什么样的字符是非法的。 具体来说，怎么定义 token 呢？接下来是定义 token 的方法 4.2.2.1 Token的定义 关键词 诸如 SELECT 、 WHERE 这一类的 token 是我们预先定义好的关键词，这类关键词是可以枚举的 比较符 诸如 &gt; 这样的字符，自己就可以成为一个单独的 token ，这一类情况和关键词类似，记为 OP 标识符 像是name, students 这些本身都不属于我们语法的一部分，是根据用户所指定的表而变化的，这部分的数据我们可以统称为 标识符 ，记为 MARK 常量 虽然上面的 SQL 语句中没有，但我们不难想到，被引号包裹的，里面的内容，不论是不是连续的，中间有没有空格，都是常量，记为 CONST 4.2.2.2 词法分析结果 最后，在定义了上面这些 token 之后，展示 词法分析 的具体结果 从形式上来说，SELECT name FROM students WHERE age &gt; 18; 可以解析成： &lt;SELECT&gt;, &lt;MARK&gt;, &lt;FROM&gt;, &lt;MARK&gt;, &lt;WHERE&gt;, &lt;MARK&gt;, &lt;OP&gt;, &lt;CONST&gt;, &lt;END&gt; 而具体来说，每一个形式上的 token 都对应一个具体的值，也就是这样的结果： SELECT, name, FROM, students, WHERE, age, &gt;, 18, ; 4.2.3 语法分析 有了 词法分析 的结果，就可以在此基础上进行 语法分析 。语法分析 的目的是检查 token 连在一起后是不是能符合我们定义的语法 ，并解析生成 抽象语法树 4.2.3.1 BNF范式的例子 在根据 BNF范式 来解析用户输入时，通常先认为用户输入的内容都属于第一条 BNF范式 ， 随后根据具体情况根据右边的表达式展开即可。 &lt;select-statement&gt; ::= SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt;; &lt;column-list&gt; ::= &lt;column-name&gt; | &lt;column-name&gt;, &lt;column-list&gt; &lt;column-name&gt; ::= &lt;MARK&gt; &lt;table-name&gt; ::= &lt;MARK&gt; &lt;MARK&gt; ::= &lt;letter&gt; {&lt;letter-or-digit&gt;} &lt;CONST&gt; ::= &#39;&lt;MARK&gt;&#39; &lt;OP&gt; ::= &lt; | = | &gt; | &lt;= | &gt;= | != &lt;letter&gt; ::= a | b | c | ... | z | A | B | C | ... | Z &lt;letter-or-digit&gt; ::= &lt;letter&gt; | &lt;digit&gt; &lt;digit&gt; ::= 0 | 1 | 2 | ... | 9 上面是一个很简单的 BNF 例子，这个例子可以解析上面给出的 SQL 语句 当然了，它也有不少不足，举例来说，上面我们给出的 BNF范式 只能解析含有一个 WHERE 条件的 SELECT 语句， BNF 是表现力很强的语言，我们可以稍作修改，让我们定义的 SELECT 语句支持任意多个 WHERE 条件： &lt;select-statement&gt; ::= SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;condition&gt; &lt;column-list&gt; ::= &lt;column-name&gt; | &lt;column-list&gt;, &lt;column-name&gt; &lt;column-name&gt; ::= &lt;MARK&gt; &lt;table-name&gt; ::= &lt;MARK&gt; &lt;condition&gt; ::= &lt;expression&gt; | &lt;condition&gt; &lt;logical-op&gt; &lt;expression&gt; &lt;expression&gt; ::= &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt; &lt;logical-op&gt; ::= AND | OR &lt;OP&gt; ::= &quot;=&quot; | &quot;&lt;&quot; | &quot;&gt;&quot; | &quot;&lt;=&quot; | &quot;&gt;=&quot; | &quot;!=&quot; &lt;MARK&gt; ::= &lt;letter&gt; {&lt;letter-or-digit&gt;} &lt;CONST&gt; ::= &#39;&lt;string&gt;&#39; &lt;string&gt; ::= {&lt;letter-or-digit&gt;} &lt;letter&gt; ::= a | b | c | ... | z | A | B | C | ... | Z &lt;letter-or-digit&gt; ::= &lt;letter&gt; | &lt;digit&gt; &lt;digit&gt; ::= 0 | 1 | 2 | ... | 9 上面的例子里给出了一个支持任意多个 WHERE 条件的 SELECT 语句的 BNF范式 在这篇文章中，我暂时不会给出 BNF范式 应该如何解读的例子，希望读者反复研读上面给出的 2 则例子，对 BNF范式 建立一个大概的印象和理解。 如果读者阅读 BNF范式 时发现很难完全理解 BNF范式 的意义，在下一篇文章中会有如何根据 BNF范式 编写程序、解析出 AST 的内容，可以参阅那部分的内容。 4.2.3.2 根据BNF范式来进行语法解析 仅仅给出 BNF范式 的方式，对没有编译原理基础的读者可能不友好，读者可能不知道应该如何利用 BNF范式 来解析语句，但在这节内容中，我们仅仅强调 BNF范式 定义的语法可以将用户输入的 SQL语句 解析为 AST。 下面，我们做一个将 SELECT 语句最后解析成 AST 的例子： 考虑下面的 SQL 语句：SELECT name FROM students WHERE age &gt; '18' AND gender = 'M'; 在完成基本的词法分析，将 SQL语句 转化成 token 后，就可以根据 BNF范式 得到以下的 抽象语法树 ： &lt;select-statement&gt; ├── &lt;column-list&gt; │ └── &lt;column-name&gt; │ └── name ├── &lt;table-name&gt; │ └── students └── &lt;condition&gt; ├── &lt;expression&gt; │ ├── &lt;MARK&gt; │ │ └── age │ ├── &lt;OP&gt; │ │ └── &gt; │ └── &lt;CONST&gt; │ └── &#39;18&#39; ├── &lt;logical-op&gt; │ └── AND └── &lt;expression&gt; ├── &lt;MARK&gt; │ └── gender ├── &lt;OP&gt; │ └── = └── &lt;CONST&gt; └── &#39;M&#39; 读者可以发现，AST树 中的所有 叶子结点 都是 BNF范式 中定义的不可继续展开(称为终止符)的，而 AST树 的 根节点 则是第一条 BNF范式。 关于如何根据 BNF 来直接解析出上面这颗 AST 的算法，在本篇文章中暂时不涉及，会在之后的篇幅中给简单介绍。 4.2.4 语义分析 在有了 AST 的基础上，可以对 AST 进行 语义分析 ，发现 AST 中符合文法逻辑，但不符合逻辑的地方。 例如，name 字段 不存在，students 这一 表 不存在，或者是age 字段 明明是数字类型，比较的值却是字符串，这一类简单的问题都可以通过语义分析来发现。 4.3 实现一个简单SQL解析器 4.3.1 自顶向下的语法解析器 让我们回忆之前提到过的可以描述 SELECT 语句的 BNF范式 ： &lt;select-statement&gt; ::= SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt;; &lt;column-list&gt; ::= &lt;column-name&gt; | &lt;column-name&gt;, &lt;column-list&gt; &lt;column-name&gt; ::= &lt;MARK&gt; &lt;table-name&gt; ::= &lt;MARK&gt; &lt;MARK&gt; ::= &lt;letter&gt; {&lt;letter-or-digit&gt;} &lt;CONST&gt; ::= &#39;&lt;MARK&gt;&#39; &lt;OP&gt; ::= &lt; | = | &gt; | &lt;= | &gt;= | != &lt;letter&gt; ::= a | b | c | ... | z | A | B | C | ... | Z &lt;letter-or-digit&gt; ::= &lt;letter&gt; | &lt;digit&gt; &lt;digit&gt; ::= 0 | 1 | 2 | ... | 9 在这篇文章中，我会一步一步介绍如何使用自顶向下的解析方式来根据 BNF范式 解析这句 SQL ： SELECT name FROM students WHERE age &gt; &#39;18&#39;; 4.3.2 BNF范式的基本概念 我们首先来回顾一下 BNF范式 ，以这条 BNF范式 为例： &lt;select-statement&gt; ::= SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt;; 在这句 BNF范式 的左侧，是一个名为 &lt;select-statement&gt; 的 非终止符 在 BNF范式 的右侧，是SELECT &lt;column-list&gt; FROM &lt;table-name&gt; WHERE &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt;;，这是一个 终止符 与 非终止符 混合的 展开式 。 其中，SELECT、FROM、WHERE、; 是 终止符 ，而 &lt;column-list&gt; &lt;table-name&gt; &lt;MARK&gt; &lt;OP&gt; &lt;CONST&gt; 是 非终止符 。 从这些描述中你可以发现，所谓的终止符就是常量，是不可以再向外推导的内容，而非终止符则有其他的 BNF范式 可以继续进行推导。 而在根据 BNF范式 推导用户输入生成 AST 时，我们总有一个起始的状态，在这里 &lt;select-statement&gt; 就是我们的起始状态。 4.3.3 根据BNF范式生成AST的过程 接下来，我以这句 SQL 为例，演示如何根据 BNF范式 、自顶向下的解析方法来生成 AST ： SELECT name FROM students WHERE age &gt; &#39;18&#39;; 4.3.3.1 生成token 不难发现，在进行了简单的 词法分析 后，上面的 SQL 语句可以解析为下面的这些 token ： SELECT (name) FROM (students) WHERE (age) (&gt;) (‘18’) 4.3.3.2 自顶向下解析 接下来，可以根据 BNF 进行解析，从最顶端的 非终止符 &lt;select-statement&gt;开始，尝试将输入的 token 匹配到这个 BNF范式 。 SELECT 是 终止符 ，它与输入的第一个 token 匹配，因此消耗这个 token 。 下一个是 &lt;column-list&gt; ，由于 BNF范式 中存在 &lt;column-list&gt; ::= &lt;column-name&gt; | &lt;column-name&gt;, &lt;column-list&gt; ，它可以继续扩展为 &lt;column-name&gt; ，又可以继续展开为 &lt;MARK&gt; 。这里 &lt;MARK&gt; 可以进一步扩展为 &lt;letter&gt; {&lt;letter-or-digit&gt;} 。在这个例子中，name 与这个模式匹配，所以消耗 token name。 下一个 终止符 是 FROM ，与输入的下一个 token 匹配，所以消耗 token FROM。 接着是 &lt;table-name&gt; 。我们的输入 token 是 &lt;letter-or-digit&gt;(students) ，它可以匹配为 &lt;table-name&gt; 中的 &lt;MARK&gt; 。此时，students 匹配 &lt;letter&gt; {&lt;letter-or-digit&gt;}，因此消耗 token students。 接下来的 终止符 WHERE 与输入的 token 匹配，所以消耗 token WHERE 。 下一个 非终止符 是 &lt;MARK&gt;，与输入的 token &lt;MARK&gt;(age) 匹配，所以消耗 token age。 下一个 终止符 &lt;OP&gt; 与输入的 token &lt;OP&gt;(&gt;) 匹配，所以消耗 token &gt;。 最后，&lt;CONST&gt; 与输入的 token &lt;CONST&gt;('18') 匹配，所以消耗token '18'。 以上，我们成功地使用 BNF范式 和 自顶向下的解析方法 ，将给定的 SQL 语句解析为一系列的 token ，并与 BNF范式 进行匹配。 4.3.3.3 生成AST（抽象语法树） 基于上述的解析过程，你可以发现，我们从第一条 BNF范式 出发，通过递归下降的方式直到我们将所有的 token 都推导为 终止符 ，而从这个推导的过程，我们可以构建一个简化的 AST ： &lt;select-statement&gt; | |-- SELECT | |-- &lt;column-list&gt; | | | |-- &lt;column-name&gt; | | | |-- name | |-- FROM | |-- &lt;table-name&gt; | | | |-- students | |-- WHERE | |-- &lt;condition&gt; | |-- &lt;MARK&gt; | | | |-- age | |-- &lt;OP&gt; | | | |-- &gt; | |-- &lt;CONST&gt; | |-- &#39;18&#39; 这样，通过自顶向下的解析方法和 BNF范式 ，我们将一个 SELECT 语句转化为了 AST ，方便之后的 语义分析 和 代码生成。 4.3.3.4 用Python实现自顶向下解析Demo 上述的过程已经很容易理解，但为了进一步明确，我把解析的过程用 python 代码实现了一下。有需要的读者可以把代码和上面的解析过程进行对照： class Node: def __init__(self, value): self.value = value self.children = [] def add_child(self, child): self.children.append(child) def __repr__(self, level=0): ret = &quot;\\t&quot; * level + repr(self.value) + &quot;\\n&quot; for child in self.children: ret += child.__repr__(level + 1) return ret def parse(tokens): current_token_index = 0 def consume(expected): nonlocal current_token_index if tokens[current_token_index] == expected: current_token_index += 1 return True return False def parse_mark(): nonlocal current_token_index node = Node(tokens[current_token_index]) current_token_index += 1 return node def parse_op(): nonlocal current_token_index node = Node(tokens[current_token_index]) current_token_index += 1 return node def parse_const(): nonlocal current_token_index node = Node(tokens[current_token_index]) current_token_index += 1 return node def parse_column_list(): node = Node(&#39;column-list&#39;) while True: node.add_child(parse_mark()) if not consume(&#39;,&#39;): break return node def parse_table_name(): node = Node(&#39;table-name&#39;) node.add_child(parse_mark()) return node def parse_where(): node = Node(&#39;Where&#39;) mark = Node(&#39;Mark&#39;) mark.add_child(parse_mark()) op = Node(&#39;OP&#39;) op.add_child(parse_op()) const = Node(&#39;Const&#39;) const.add_child(parse_const()) node.add_child(mark) node.add_child(op) node.add_child(const) return node def parse_select_statement(): # 解析入口 root = Node(&#39;select-statement&#39;) if not consume(&#39;SELECT&#39;): raise ValueError(&quot;Expected &#39;SELECT&#39;&quot;) root.add_child(parse_column_list()) if not consume(&#39;FROM&#39;): raise ValueError(&quot;Expected &#39;FROM&#39;&quot;) root.add_child(parse_table_name()) if not consume(&#39;WHERE&#39;): raise ValueError(&quot;Expected &#39;WHERE&#39;&quot;) root.add_child(parse_where()) return root return parse_select_statement() # 已经分好的token tokens = [&#39;SELECT&#39;, &#39;name&#39;, &#39;FROM&#39;, &#39;students&#39;, &#39;WHERE&#39;, &#39;age&#39;, &#39;&gt;&#39;, &quot;&#39;18&#39;&quot;] # 自顶向下解析 ast = parse(tokens) print(ast) 上面的 python 代码完全复现了之前描述的自顶向下解析过程，根据 词法分析 的结果解析出了一颗 抽象语法树 ，下面是运行的结果： &#39;select-statement&#39; &#39;column-list&#39; &#39;name&#39; &#39;table-name&#39; &#39;students&#39; &#39;Where&#39; &#39;Mark&#39; &#39;age&#39; &#39;OP&#39; &#39;&gt;&#39; &#39;Const&#39; &quot;&#39;18&#39;&quot; 4.3.4 LL(1)解析器 需要指出，编译原理其实是相对复杂的，这里我们使用的 语法分析 方式只是所有语法分析方式中最简单的一种。 具体来说，我们的解析方式总是从左至右解析，并且总是只预读1个 Token ，这样的解析方式被称为 LL(1) ，我们实现的解析器是一个 LL(1) 解析器。 这种方式有它的局限性，例如，它不能处理含有左递归的语法规则，不能处理需要预读 1 个以上 Token 的复杂语法，并且，和自顶向下解析相对应地，也存在自底向上的解析方式，事实上，自底向上的解析方式更能够适应复杂的文法，在业界被广泛使用。 "],["intro-to-store.html", "第 5 章 存储基础 5.1 硬盘与操作系统", " 第 5 章 存储基础 5.1 硬盘与操作系统 大家都知道数据是存储在硬盘上的，这篇文章会重点讨论硬盘与操作系统是如何交互的，这部分的讨论侧重于软件的讨论，硬盘还有一些值得注意的硬件特性，例如高延迟、随机读写性能差、读写放大等特性，会在另外的文章中讨论。 5.1.1 操作系统如何认识硬盘 目前，硬盘已经有多种不同的物理接口，消费级硬件中主流的是 SATA 和 NGFF (M.2) 接口的硬盘，SATA 接口的硬盘几乎一定默认使用 AHCI 协议与操作系统进行交互，而 NGFF 接口的硬盘可能会存在支持 AHCI 和 NVMe 两种不同协议的硬盘，彼此之间不互相兼容。 本文要讨论的是操作系统与硬件交互的标准方式，也就是类似软件上接口(interface)的概念，因此本文主要讨论的是AHCI或者NVMe，而不是SATA或者NGFF。 5.1.2 操作系统对硬盘的抽象 以 AHCI 协议为例，AHCI 协议是 Intel 牵头制定的，官方有详细的协议规范： https://www.intel.com/content/www/us/en/io/serial-ata/serial-ata-ahci-spec-rev1-3-1.html 这份规范是非常底层的，直接说明了操作系统与硬件如何交互： 图 5.1: 规范中对数据FIS传输的说明 抽象来说，AHCI 包括了一些命令，操作系统可以通过操作内存来调用这些命令，下面是我抽象的几个指令： 指令 作用 Read Sector 用来读取一个或者多个扇区的数据 Write Sector 用来写入一个或者多个扇区的数据 Identify Device 获取设备描述信息 Flush Cache 强制硬盘将缓存中的数据写入到盘上 Standby Immediate 提示硬盘从待机状态恢复到工作状态 Idle Immediate 提示硬盘从工作状态切换到低功耗待机模式 Data Set Management 用来提示硬盘进行TRIM等操作（SSD和Host managed SMR盘常用） Read FPDMA Queued 将一个读取指令加入到硬盘本地的队列中，硬盘可以乱序执行队列中的指令来获得最佳性能 Write FPDMA Queued 将一个写入指令加入到硬盘本地的队列中，硬盘可以乱序执行队列中的指令来获得最佳性能 其中的很多指令都很容易理解，例如Read Sector，就是读取数据的指令，Idle Immediate 是对硬盘电源状态进行管理的指令，我想，读者可能会对Data Set Management 这一指令的作用有些困惑，这里就对这个做一下展开解释。 SSD 和 Host-Managed SMR 硬盘有一个特性：在写入数据前必须先擦除掉这部分的数据，而擦除需要花费不少时间。因此，操作系统可以通过这些指令在文件删除时就通知 SSD：这片区域不再使用了，SSD 就会在空闲时进行擦除操作，节省下次写入时需要的时间。这种操作可以认为是一种垃圾回收过程，不过需要注意其与内存管理中的垃圾回收有明显区别。 除了对 AHCI 的底层命令进行抽象封装外，操作系统还进行了一系列额外的工作，这部分工作视操作系统的不同而不同。例如，在 Linux 系统中，所有的硬盘都被抽象为块设备： # lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 20G 0 disk ├─sda1 8:1 0 476M 0 part /boot └─sda2 8:2 0 19.5G 0 part / 通过上面的命令可以看出，在这台系统上有 20G 的硬盘，这块硬盘分为 2 个分区，被 Linux 系统识别为sda的块设备。 下一节，我们简单聊一聊 Linux 系统中的“块设备”的特性和使用方法。 5.1.3 块设备(Block device) 为什么 Linux 系统将硬盘抽象成块设备？块设备是什么含义？ 块设备在 Linux 系统上是指能够按照固定大小的块进行数据存取的设备，例如，对于扇区大小是 512B 的硬盘来说，块的大小就是 512B ，在 Linux 系统上，下面所有的设备都是块设备： 设备名称 设备类型 /dev/sdX AHCI设备 /dev/sr0 光驱 /dev/hdX IDE设备 /dev/nvmeX NVMe设备 /dev/mmcblkX MMC设备(eMMC或者SD卡) 在 Unix 系统中，一切都是文件，因此，块设备作为文件也实现了文件的基本接口，可以被标准的文件 API 读取和写入： # sudo head -c 8 /dev/sda ?c??м# 以上的命令使用 head 工具读取了硬盘最开始的 8 个字节的数据，当然了，展示出来的是乱码，因为这些二进制数据不是用 ASCII 编码的。 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
